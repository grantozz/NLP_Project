{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "sys.path.append('skip-thoughts.torch/pytorch')\n",
    "from skipthoughts import UniSkip,BiSkip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Vocabulary import Vocabulary, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vocab(tokens):\n",
    "    voc = Vocabulary(['<PAD>','<UNK>'])\n",
    "    voc.add_tokens(tokens)\n",
    "    print('vocab len is {}'.format(len(voc.w2idx)))\n",
    "    return voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file='story_cloze_data/cloze_test_val__spring2016 - cloze_test_ALL_val.csv'):\n",
    "    df= pd.read_csv(file)\n",
    "    df = df.drop('InputStoryid',axis=1)\n",
    "    targets = df['AnswerRightEnding']\n",
    "    df = df.drop('AnswerRightEnding',axis=1)\n",
    "    df = df.drop('InputSentence1',axis=1)\n",
    "    df = df.drop('InputSentence2',axis=1)\n",
    "    df = df.drop('InputSentence3',axis=1)\n",
    "    \n",
    "    voc_str= ''\n",
    "    for index, row in df.iterrows():\n",
    "        voc_str+=' '.join(list(row)) + ' '\n",
    "        \n",
    "    df['AnswerRightEnding'] = targets\n",
    "    return df,make_vocab(preprocess(voc_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "class NoContextDataset(Dataset):\n",
    "    def __init__(self,file='story_cloze_data/cloze_test_val__spring2016 - cloze_test_ALL_val.csv',vocab=None,df=None):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        created_df, created_vocab = load_data(file)\n",
    "        if df is None:\n",
    "            df = created_df\n",
    "        if vocab:\n",
    "            self.vocab = vocab\n",
    "        else:\n",
    "            self.vocab = created_vocab\n",
    "        #self.df = df\n",
    "      \n",
    "        \n",
    "        self.dir_st = 'data/skip-thoughts'\n",
    "        self.biskip = BiSkip(self.dir_st, self.vocab.convert_to_list()[1:])\n",
    "        \n",
    "        self.uniskip = UniSkip(self.dir_st, self.vocab.convert_to_list()[1:])\n",
    "        \n",
    "        \n",
    "        self.data = self.make_data(df)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            idx\n",
    "        Returns: skip thought embedding of ending and 0/1 if it is the right ending \n",
    "\n",
    "        \"\"\"\n",
    "        return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns len of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "       \n",
    "    def make_data(self, df):\n",
    "        data = []\n",
    "        total = df.index\n",
    "        print('skip thought encoding dataset')\n",
    "        for i in total:\n",
    "            progress(i,len(total))\n",
    "            endings =  self.gen_embbeding(df.at[i,'RandomFifthSentenceQuiz1'], df.at[i,'RandomFifthSentenceQuiz2'])\n",
    "            if df.at[i,'AnswerRightEnding'] == 1:\n",
    "                data.append((endings[0].detach().numpy(),1))\n",
    "                data.append((endings[1].detach().numpy(),0))\n",
    "            else:\n",
    "                data.append((endings[0].detach().numpy(),0))\n",
    "                data.append((endings[1].detach().numpy(),1))\n",
    "        return data\n",
    "    \n",
    "\n",
    "    def zero_pad(self,l,n):\n",
    "        l = (l + n * [0])[:n]\n",
    "        return l\n",
    "    \n",
    "    def pad_input(self,a,b):\n",
    "        ed = sorted([a,b],key=len)\n",
    "        longer = ed[1]\n",
    "        shorter = ed[0]\n",
    "        padded = self.zero_pad( shorter,len(longer))\n",
    "        if shorter == a:\n",
    "            return padded,b\n",
    "        else: return a,padded\n",
    "        \n",
    "    def gen_embbeding(self,sent1,sent2):\n",
    "        sent1 = preprocess(sent1)\n",
    "        sent2 = preprocess(sent2)\n",
    "        #remove random n token that is in one sentence\n",
    "        if 'n' in sent2:\n",
    "            sent2.remove('n')\n",
    "        encoded_end1 = self.vocab.get_sentence(sent1)\n",
    "        encoded_end2 = self.vocab.get_sentence(sent2)\n",
    "        a,b = self.pad_input(encoded_end1,encoded_end2)\n",
    "        \n",
    "        batch = torch.LongTensor([a,b]) \n",
    "        top_half = self.uniskip(batch)\n",
    "        bottom_half = self.biskip(batch)\n",
    "        combine_skip = torch.cat([top_half,bottom_half],dim=1) \n",
    "        return combine_skip    \n",
    "    \n",
    "def progress(count, total, status=''):\n",
    "    bar_len = 60\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "\n",
    "    percents = round(100.0 * count / float(total), 1)\n",
    "    bar = '=' * filled_len + '-' * (bar_len - filled_len)\n",
    "\n",
    "    sys.stdout.write('[%s] %s%s ...%s\\r' % (bar, percents, '%', status))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoContextModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input = torch.nn.Linear(4800,256)\n",
    "        self.hidden= torch.nn.Linear(256,64)\n",
    "        self.output = torch.nn.Linear(64,2)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        hidden = torch.nn.functional.relu(self.input(inputs))\n",
    "        hidden1 = torch.nn.functional.relu(self.hidden(hidden))\n",
    "        output = self.output(hidden1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(pair,model):\n",
    "    '''true if model predicts right'''\n",
    "    ending1, ending2 = pair\n",
    "    if ending1[1] == 1:\n",
    "        target = 1\n",
    "    else:\n",
    "        target =  2 \n",
    "        \n",
    "    ending1 = torch.tensor(ending1[0])\n",
    "    ending2 = torch.tensor(ending2[0])\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        ending1 = ending1.cuda()\n",
    "        ending2 = ending2.cuda()\n",
    "    res1 = model(ending1)\n",
    "    res2 = model(ending2)\n",
    "    softm = torch.nn.Softmax(dim=0)\n",
    "    prob_end1_right = softm(res1)[1].item() \n",
    "    prob_end2_right = softm(res2)[1].item()\n",
    "    \n",
    "    if prob_end1_right > prob_end2_right:\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 2\n",
    "    \n",
    "    if pred == target:\n",
    "        return True\n",
    "    else: \n",
    "        #print(prob_end1_right,prob_end2_right,pred,target)\n",
    "        return False\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(data_set):\n",
    "    num_right = 0\n",
    "    for i in range(0,len(data_set),2):\n",
    "        if score((data_set[i],data_set[i+1]),model):\n",
    "            num_right+=1\n",
    "    return num_right / (len(data_set)/2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(name):\n",
    "    torch.save(model.state_dict(), 'saved_models/{}.save'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-paper')\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "num_epochs = 30\n",
    "report_every = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab len is 5303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df, voc = load_data()\n",
    "train, val = train_test_split(df, test_size=0.1,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab len is 5303\n",
      "Warning: 46/930911 words are not in dictionary, thus set UNK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grant/Desktop/school/nlp/env/lib/python3.6/site-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 46/930911 words are not in dictionary, thus set UNK\n",
      "skip thought encoding dataset\n",
      "[============================================================] 99.9% ...\r"
     ]
    }
   ],
   "source": [
    "train_data_set = NoContextDataset(df=train,vocab=voc)\n",
    "data_loader = torch.utils.data.DataLoader(train_data_set, batch_size=batch_size, shuffle=True,num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab len is 5303\n",
      "Warning: 46/930911 words are not in dictionary, thus set UNK\n",
      "Warning: 46/930911 words are not in dictionary, thus set UNK\n",
      "skip thought encoding dataset\n",
      "[=====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] 994.7% ...\r"
     ]
    }
   ],
   "source": [
    "val_data_set = NoContextDataset(file='story_cloze_data/cloze_test_val__spring2016 - cloze_test_ALL_val.csv',df=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NoContextModel()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Loss 0.4957. accuracy 0.7660. Elapsed 1 seconds\n",
      "Epoch 1. Loss 0.4908. accuracy 0.7660. Elapsed 1 seconds\n",
      "Epoch 1. Loss 0.5005. accuracy 0.7606. Elapsed 1 seconds\n",
      "Epoch 1. Loss 0.5009. accuracy 0.7606. Elapsed 2 seconds\n",
      "Epoch 1. Loss 0.5155. accuracy 0.7660. Elapsed 2 seconds\n",
      "Epoch 1. Loss 0.5223. accuracy 0.7660. Elapsed 3 seconds\n",
      "Epoch 1. Loss 0.5196. accuracy 0.7660. Elapsed 3 seconds\n",
      "Epoch 1. Loss 0.5153. accuracy 0.7606. Elapsed 4 seconds\n",
      "Epoch 1. Loss 0.5104. accuracy 0.7606. Elapsed 4 seconds\n",
      "Epoch 1. Loss 0.5068. accuracy 0.7660. Elapsed 5 seconds\n",
      "Epoch 1. Loss 0.5083. accuracy 0.7660. Elapsed 5 seconds\n",
      "Epoch 1. Loss 0.5105. accuracy 0.7660. Elapsed 5 seconds\n",
      "Epoch 1. Loss 0.5117. accuracy 0.7660. Elapsed 6 seconds\n",
      "Epoch 1. Loss 0.5131. accuracy 0.7606. Elapsed 6 seconds\n",
      "Epoch 1. Loss 0.5131. accuracy 0.7606. Elapsed 6 seconds\n",
      "Epoch 1. Loss 0.5115. accuracy 0.7553. Elapsed 7 seconds\n",
      "Epoch 1. Loss 0.5131. accuracy 0.7606. Elapsed 7 seconds\n",
      "Epoch 1. Loss 0.5124. accuracy 0.7606. Elapsed 8 seconds\n",
      "Epoch 1. Loss 0.5136. accuracy 0.7606. Elapsed 8 seconds\n",
      "Epoch 1. Loss 0.5133. accuracy 0.7606. Elapsed 8 seconds\n",
      "Epoch 1. Loss 0.5143. accuracy 0.7553. Elapsed 9 seconds\n",
      "Epoch 1. Loss 0.5175. accuracy 0.7606. Elapsed 9 seconds\n",
      "Epoch 1. Loss 0.5158. accuracy 0.7553. Elapsed 9 seconds\n",
      "Epoch 1. Loss 0.5179. accuracy 0.7553. Elapsed 10 seconds\n",
      "Epoch 1. Loss 0.5171. accuracy 0.7553. Elapsed 10 seconds\n",
      "Epoch 1. Loss 0.5153. accuracy 0.7660. Elapsed 11 seconds\n",
      "Epoch 1. Loss 0.5143. accuracy 0.7606. Elapsed 11 seconds\n",
      "ep acc 0.7616233254531126\n",
      "new best saving model\n",
      "Epoch 2. Loss 0.4685. accuracy 0.7660. Elapsed 11 seconds\n",
      "Epoch 2. Loss 0.4750. accuracy 0.7553. Elapsed 11 seconds\n",
      "Epoch 2. Loss 0.4843. accuracy 0.7500. Elapsed 12 seconds\n",
      "Epoch 2. Loss 0.4886. accuracy 0.7606. Elapsed 12 seconds\n",
      "Epoch 2. Loss 0.5054. accuracy 0.7553. Elapsed 12 seconds\n",
      "Epoch 2. Loss 0.5046. accuracy 0.7500. Elapsed 13 seconds\n",
      "Epoch 2. Loss 0.5033. accuracy 0.7447. Elapsed 13 seconds\n",
      "Epoch 2. Loss 0.5035. accuracy 0.7606. Elapsed 13 seconds\n",
      "Epoch 2. Loss 0.5059. accuracy 0.7500. Elapsed 14 seconds\n",
      "Epoch 2. Loss 0.5052. accuracy 0.7500. Elapsed 14 seconds\n",
      "Epoch 2. Loss 0.5014. accuracy 0.7500. Elapsed 14 seconds\n",
      "Epoch 2. Loss 0.5065. accuracy 0.7500. Elapsed 14 seconds\n",
      "Epoch 2. Loss 0.5083. accuracy 0.7500. Elapsed 15 seconds\n",
      "Epoch 2. Loss 0.5105. accuracy 0.7553. Elapsed 15 seconds\n",
      "Epoch 2. Loss 0.5131. accuracy 0.7394. Elapsed 15 seconds\n",
      "Epoch 2. Loss 0.5172. accuracy 0.7447. Elapsed 16 seconds\n",
      "Epoch 2. Loss 0.5160. accuracy 0.7447. Elapsed 16 seconds\n",
      "Epoch 2. Loss 0.5171. accuracy 0.7500. Elapsed 16 seconds\n",
      "Epoch 2. Loss 0.5169. accuracy 0.7500. Elapsed 17 seconds\n",
      "Epoch 2. Loss 0.5151. accuracy 0.7553. Elapsed 17 seconds\n",
      "Epoch 2. Loss 0.5142. accuracy 0.7553. Elapsed 18 seconds\n",
      "Epoch 2. Loss 0.5131. accuracy 0.7553. Elapsed 18 seconds\n",
      "Epoch 2. Loss 0.5118. accuracy 0.7553. Elapsed 18 seconds\n",
      "Epoch 2. Loss 0.5106. accuracy 0.7606. Elapsed 18 seconds\n",
      "Epoch 2. Loss 0.5111. accuracy 0.7553. Elapsed 19 seconds\n",
      "Epoch 2. Loss 0.5096. accuracy 0.7606. Elapsed 19 seconds\n",
      "Epoch 2. Loss 0.5100. accuracy 0.7500. Elapsed 20 seconds\n",
      "ep acc 0.7571907013396376\n",
      "Epoch 3. Loss 0.4825. accuracy 0.7500. Elapsed 20 seconds\n",
      "Epoch 3. Loss 0.4850. accuracy 0.7553. Elapsed 20 seconds\n",
      "Epoch 3. Loss 0.4909. accuracy 0.7606. Elapsed 20 seconds\n",
      "Epoch 3. Loss 0.4859. accuracy 0.7500. Elapsed 21 seconds\n",
      "Epoch 3. Loss 0.4813. accuracy 0.7447. Elapsed 21 seconds\n",
      "Epoch 3. Loss 0.4944. accuracy 0.7447. Elapsed 22 seconds\n",
      "Epoch 3. Loss 0.4930. accuracy 0.7500. Elapsed 22 seconds\n",
      "Epoch 3. Loss 0.5002. accuracy 0.7500. Elapsed 22 seconds\n",
      "Epoch 3. Loss 0.4966. accuracy 0.7500. Elapsed 22 seconds\n",
      "Epoch 3. Loss 0.5013. accuracy 0.7500. Elapsed 23 seconds\n",
      "Epoch 3. Loss 0.5052. accuracy 0.7447. Elapsed 23 seconds\n",
      "Epoch 3. Loss 0.5016. accuracy 0.7394. Elapsed 23 seconds\n",
      "Epoch 3. Loss 0.5032. accuracy 0.7394. Elapsed 24 seconds\n",
      "Epoch 3. Loss 0.5030. accuracy 0.7447. Elapsed 24 seconds\n",
      "Epoch 3. Loss 0.5042. accuracy 0.7500. Elapsed 24 seconds\n",
      "Epoch 3. Loss 0.5022. accuracy 0.7394. Elapsed 25 seconds\n",
      "Epoch 3. Loss 0.5012. accuracy 0.7447. Elapsed 25 seconds\n",
      "Epoch 3. Loss 0.5054. accuracy 0.7500. Elapsed 26 seconds\n",
      "Epoch 3. Loss 0.5067. accuracy 0.7447. Elapsed 26 seconds\n",
      "Epoch 3. Loss 0.5097. accuracy 0.7500. Elapsed 26 seconds\n",
      "Epoch 3. Loss 0.5089. accuracy 0.7500. Elapsed 27 seconds\n",
      "Epoch 3. Loss 0.5074. accuracy 0.7500. Elapsed 27 seconds\n",
      "Epoch 3. Loss 0.5095. accuracy 0.7500. Elapsed 27 seconds\n",
      "Epoch 3. Loss 0.5105. accuracy 0.7500. Elapsed 28 seconds\n",
      "Epoch 3. Loss 0.5079. accuracy 0.7500. Elapsed 28 seconds\n",
      "Epoch 3. Loss 0.5063. accuracy 0.7500. Elapsed 28 seconds\n",
      "Epoch 3. Loss 0.5053. accuracy 0.7553. Elapsed 28 seconds\n",
      "ep acc 0.7542684528500131\n",
      "Epoch 4. Loss 0.4596. accuracy 0.7500. Elapsed 29 seconds\n",
      "Epoch 4. Loss 0.5028. accuracy 0.7500. Elapsed 29 seconds\n",
      "Epoch 4. Loss 0.5037. accuracy 0.7500. Elapsed 29 seconds\n",
      "Epoch 4. Loss 0.5025. accuracy 0.7500. Elapsed 30 seconds\n",
      "Epoch 4. Loss 0.4960. accuracy 0.7447. Elapsed 30 seconds\n",
      "Epoch 4. Loss 0.5037. accuracy 0.7447. Elapsed 30 seconds\n",
      "Epoch 4. Loss 0.5041. accuracy 0.7500. Elapsed 30 seconds\n",
      "Epoch 4. Loss 0.5069. accuracy 0.7500. Elapsed 31 seconds\n",
      "Epoch 4. Loss 0.5032. accuracy 0.7447. Elapsed 31 seconds\n",
      "Epoch 4. Loss 0.5049. accuracy 0.7500. Elapsed 31 seconds\n",
      "Epoch 4. Loss 0.5083. accuracy 0.7500. Elapsed 31 seconds\n",
      "Epoch 4. Loss 0.5042. accuracy 0.7447. Elapsed 31 seconds\n",
      "Epoch 4. Loss 0.5089. accuracy 0.7500. Elapsed 32 seconds\n",
      "Epoch 4. Loss 0.5051. accuracy 0.7553. Elapsed 32 seconds\n",
      "Epoch 4. Loss 0.5052. accuracy 0.7500. Elapsed 32 seconds\n",
      "Epoch 4. Loss 0.5060. accuracy 0.7500. Elapsed 33 seconds\n",
      "Epoch 4. Loss 0.5027. accuracy 0.7447. Elapsed 33 seconds\n",
      "Epoch 4. Loss 0.5022. accuracy 0.7447. Elapsed 33 seconds\n",
      "Epoch 4. Loss 0.5006. accuracy 0.7447. Elapsed 33 seconds\n",
      "Epoch 4. Loss 0.5021. accuracy 0.7447. Elapsed 34 seconds\n",
      "Epoch 4. Loss 0.5015. accuracy 0.7447. Elapsed 34 seconds\n",
      "Epoch 4. Loss 0.5004. accuracy 0.7447. Elapsed 34 seconds\n",
      "Epoch 4. Loss 0.5010. accuracy 0.7500. Elapsed 35 seconds\n",
      "Epoch 4. Loss 0.5014. accuracy 0.7500. Elapsed 35 seconds\n",
      "Epoch 4. Loss 0.5027. accuracy 0.7447. Elapsed 35 seconds\n",
      "Epoch 4. Loss 0.5011. accuracy 0.7500. Elapsed 35 seconds\n",
      "Epoch 4. Loss 0.5036. accuracy 0.7447. Elapsed 36 seconds\n",
      "ep acc 0.7526595744680852\n",
      "Epoch 5. Loss 0.4919. accuracy 0.7447. Elapsed 36 seconds\n",
      "Epoch 5. Loss 0.4821. accuracy 0.7447. Elapsed 36 seconds\n",
      "Epoch 5. Loss 0.4892. accuracy 0.7500. Elapsed 36 seconds\n",
      "Epoch 5. Loss 0.4881. accuracy 0.7500. Elapsed 37 seconds\n",
      "Epoch 5. Loss 0.4929. accuracy 0.7447. Elapsed 37 seconds\n",
      "Epoch 5. Loss 0.5022. accuracy 0.7447. Elapsed 37 seconds\n",
      "Epoch 5. Loss 0.5016. accuracy 0.7447. Elapsed 37 seconds\n",
      "Epoch 5. Loss 0.5030. accuracy 0.7447. Elapsed 38 seconds\n",
      "Epoch 5. Loss 0.5088. accuracy 0.7447. Elapsed 38 seconds\n",
      "Epoch 5. Loss 0.5091. accuracy 0.7447. Elapsed 38 seconds\n",
      "Epoch 5. Loss 0.5074. accuracy 0.7447. Elapsed 38 seconds\n",
      "Epoch 5. Loss 0.5071. accuracy 0.7447. Elapsed 39 seconds\n",
      "Epoch 5. Loss 0.5032. accuracy 0.7447. Elapsed 39 seconds\n",
      "Epoch 5. Loss 0.5043. accuracy 0.7447. Elapsed 39 seconds\n",
      "Epoch 5. Loss 0.5033. accuracy 0.7447. Elapsed 40 seconds\n",
      "Epoch 5. Loss 0.5002. accuracy 0.7447. Elapsed 40 seconds\n",
      "Epoch 5. Loss 0.4988. accuracy 0.7447. Elapsed 40 seconds\n",
      "Epoch 5. Loss 0.5005. accuracy 0.7500. Elapsed 41 seconds\n",
      "Epoch 5. Loss 0.5008. accuracy 0.7500. Elapsed 41 seconds\n",
      "Epoch 5. Loss 0.4998. accuracy 0.7447. Elapsed 41 seconds\n",
      "Epoch 5. Loss 0.5004. accuracy 0.7447. Elapsed 41 seconds\n",
      "Epoch 5. Loss 0.5023. accuracy 0.7447. Elapsed 42 seconds\n",
      "Epoch 5. Loss 0.5002. accuracy 0.7447. Elapsed 42 seconds\n",
      "Epoch 5. Loss 0.4990. accuracy 0.7447. Elapsed 42 seconds\n",
      "Epoch 5. Loss 0.4980. accuracy 0.7447. Elapsed 42 seconds\n",
      "Epoch 5. Loss 0.4980. accuracy 0.7447. Elapsed 43 seconds\n",
      "Epoch 5. Loss 0.4949. accuracy 0.7447. Elapsed 43 seconds\n",
      "ep acc 0.7512214342001574\n",
      "Epoch 6. Loss 0.4825. accuracy 0.7447. Elapsed 43 seconds\n",
      "Epoch 6. Loss 0.4745. accuracy 0.7447. Elapsed 44 seconds\n",
      "Epoch 6. Loss 0.4578. accuracy 0.7447. Elapsed 44 seconds\n",
      "Epoch 6. Loss 0.4558. accuracy 0.7447. Elapsed 44 seconds\n",
      "Epoch 6. Loss 0.4643. accuracy 0.7447. Elapsed 45 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6. Loss 0.4676. accuracy 0.7500. Elapsed 45 seconds\n",
      "Epoch 6. Loss 0.4771. accuracy 0.7500. Elapsed 46 seconds\n",
      "Epoch 6. Loss 0.4823. accuracy 0.7500. Elapsed 46 seconds\n",
      "Epoch 6. Loss 0.4872. accuracy 0.7500. Elapsed 46 seconds\n",
      "Epoch 6. Loss 0.4821. accuracy 0.7500. Elapsed 47 seconds\n",
      "Epoch 6. Loss 0.4833. accuracy 0.7500. Elapsed 47 seconds\n",
      "Epoch 6. Loss 0.4874. accuracy 0.7447. Elapsed 47 seconds\n",
      "Epoch 6. Loss 0.4891. accuracy 0.7447. Elapsed 48 seconds\n",
      "Epoch 6. Loss 0.4861. accuracy 0.7447. Elapsed 48 seconds\n",
      "Epoch 6. Loss 0.4874. accuracy 0.7447. Elapsed 48 seconds\n",
      "Epoch 6. Loss 0.4885. accuracy 0.7447. Elapsed 49 seconds\n",
      "Epoch 6. Loss 0.4921. accuracy 0.7447. Elapsed 49 seconds\n",
      "Epoch 6. Loss 0.4913. accuracy 0.7447. Elapsed 49 seconds\n",
      "Epoch 6. Loss 0.4916. accuracy 0.7447. Elapsed 49 seconds\n",
      "Epoch 6. Loss 0.4890. accuracy 0.7447. Elapsed 50 seconds\n",
      "Epoch 6. Loss 0.4915. accuracy 0.7447. Elapsed 50 seconds\n",
      "Epoch 6. Loss 0.4911. accuracy 0.7447. Elapsed 50 seconds\n",
      "Epoch 6. Loss 0.4925. accuracy 0.7447. Elapsed 51 seconds\n",
      "Epoch 6. Loss 0.4922. accuracy 0.7447. Elapsed 51 seconds\n",
      "Epoch 6. Loss 0.4923. accuracy 0.7447. Elapsed 51 seconds\n",
      "Epoch 6. Loss 0.4941. accuracy 0.7500. Elapsed 52 seconds\n",
      "Epoch 6. Loss 0.4899. accuracy 0.7500. Elapsed 52 seconds\n",
      "ep acc 0.7503940110323088\n",
      "Epoch 7. Loss 0.4806. accuracy 0.7447. Elapsed 52 seconds\n",
      "Epoch 7. Loss 0.4901. accuracy 0.7447. Elapsed 53 seconds\n",
      "Epoch 7. Loss 0.5063. accuracy 0.7447. Elapsed 53 seconds\n",
      "Epoch 7. Loss 0.5083. accuracy 0.7447. Elapsed 53 seconds\n",
      "Epoch 7. Loss 0.5048. accuracy 0.7447. Elapsed 54 seconds\n",
      "Epoch 7. Loss 0.5016. accuracy 0.7447. Elapsed 54 seconds\n",
      "Epoch 7. Loss 0.5040. accuracy 0.7447. Elapsed 54 seconds\n",
      "Epoch 7. Loss 0.4969. accuracy 0.7447. Elapsed 54 seconds\n",
      "Epoch 7. Loss 0.4947. accuracy 0.7447. Elapsed 55 seconds\n",
      "Epoch 7. Loss 0.4973. accuracy 0.7500. Elapsed 55 seconds\n",
      "Epoch 7. Loss 0.4916. accuracy 0.7500. Elapsed 55 seconds\n",
      "Epoch 7. Loss 0.4910. accuracy 0.7500. Elapsed 55 seconds\n",
      "Epoch 7. Loss 0.4908. accuracy 0.7500. Elapsed 56 seconds\n",
      "Epoch 7. Loss 0.4923. accuracy 0.7500. Elapsed 56 seconds\n",
      "Epoch 7. Loss 0.4934. accuracy 0.7500. Elapsed 56 seconds\n",
      "Epoch 7. Loss 0.4923. accuracy 0.7500. Elapsed 56 seconds\n",
      "Epoch 7. Loss 0.4893. accuracy 0.7500. Elapsed 57 seconds\n",
      "Epoch 7. Loss 0.4880. accuracy 0.7500. Elapsed 57 seconds\n",
      "Epoch 7. Loss 0.4861. accuracy 0.7447. Elapsed 57 seconds\n",
      "Epoch 7. Loss 0.4872. accuracy 0.7447. Elapsed 57 seconds\n",
      "Epoch 7. Loss 0.4855. accuracy 0.7447. Elapsed 58 seconds\n",
      "Epoch 7. Loss 0.4867. accuracy 0.7447. Elapsed 58 seconds\n",
      "Epoch 7. Loss 0.4869. accuracy 0.7447. Elapsed 58 seconds\n",
      "Epoch 7. Loss 0.4853. accuracy 0.7447. Elapsed 58 seconds\n",
      "Epoch 7. Loss 0.4851. accuracy 0.7447. Elapsed 59 seconds\n",
      "Epoch 7. Loss 0.4880. accuracy 0.7447. Elapsed 59 seconds\n",
      "Epoch 7. Loss 0.4866. accuracy 0.7500. Elapsed 59 seconds\n",
      "ep acc 0.7498592817741755\n",
      "Epoch 8. Loss 0.5089. accuracy 0.7500. Elapsed 59 seconds\n",
      "Epoch 8. Loss 0.4935. accuracy 0.7500. Elapsed 60 seconds\n",
      "Epoch 8. Loss 0.4729. accuracy 0.7500. Elapsed 60 seconds\n",
      "Epoch 8. Loss 0.4580. accuracy 0.7447. Elapsed 60 seconds\n",
      "Epoch 8. Loss 0.4649. accuracy 0.7447. Elapsed 61 seconds\n",
      "Epoch 8. Loss 0.4689. accuracy 0.7447. Elapsed 61 seconds\n",
      "Epoch 8. Loss 0.4730. accuracy 0.7447. Elapsed 61 seconds\n",
      "Epoch 8. Loss 0.4738. accuracy 0.7500. Elapsed 61 seconds\n",
      "Epoch 8. Loss 0.4697. accuracy 0.7394. Elapsed 62 seconds\n",
      "Epoch 8. Loss 0.4707. accuracy 0.7447. Elapsed 62 seconds\n",
      "Epoch 8. Loss 0.4705. accuracy 0.7447. Elapsed 62 seconds\n",
      "Epoch 8. Loss 0.4688. accuracy 0.7500. Elapsed 62 seconds\n",
      "Epoch 8. Loss 0.4713. accuracy 0.7447. Elapsed 63 seconds\n",
      "Epoch 8. Loss 0.4719. accuracy 0.7447. Elapsed 63 seconds\n",
      "Epoch 8. Loss 0.4729. accuracy 0.7447. Elapsed 63 seconds\n",
      "Epoch 8. Loss 0.4748. accuracy 0.7447. Elapsed 64 seconds\n",
      "Epoch 8. Loss 0.4769. accuracy 0.7447. Elapsed 64 seconds\n",
      "Epoch 8. Loss 0.4789. accuracy 0.7500. Elapsed 64 seconds\n",
      "Epoch 8. Loss 0.4820. accuracy 0.7500. Elapsed 64 seconds\n",
      "Epoch 8. Loss 0.4860. accuracy 0.7500. Elapsed 65 seconds\n",
      "Epoch 8. Loss 0.4853. accuracy 0.7500. Elapsed 65 seconds\n",
      "Epoch 8. Loss 0.4881. accuracy 0.7500. Elapsed 65 seconds\n",
      "Epoch 8. Loss 0.4889. accuracy 0.7500. Elapsed 65 seconds\n",
      "Epoch 8. Loss 0.4877. accuracy 0.7500. Elapsed 66 seconds\n",
      "Epoch 8. Loss 0.4881. accuracy 0.7500. Elapsed 66 seconds\n",
      "Epoch 8. Loss 0.4861. accuracy 0.7500. Elapsed 66 seconds\n",
      "Epoch 8. Loss 0.4861. accuracy 0.7500. Elapsed 66 seconds\n",
      "ep acc 0.7495567375886525\n",
      "Epoch 9. Loss 0.4930. accuracy 0.7500. Elapsed 66 seconds\n",
      "Epoch 9. Loss 0.4655. accuracy 0.7500. Elapsed 67 seconds\n",
      "Epoch 9. Loss 0.4635. accuracy 0.7500. Elapsed 67 seconds\n",
      "Epoch 9. Loss 0.4675. accuracy 0.7500. Elapsed 67 seconds\n",
      "Epoch 9. Loss 0.4718. accuracy 0.7500. Elapsed 67 seconds\n",
      "Epoch 9. Loss 0.4779. accuracy 0.7500. Elapsed 68 seconds\n",
      "Epoch 9. Loss 0.4831. accuracy 0.7500. Elapsed 68 seconds\n",
      "Epoch 9. Loss 0.4844. accuracy 0.7500. Elapsed 68 seconds\n",
      "Epoch 9. Loss 0.4879. accuracy 0.7500. Elapsed 68 seconds\n",
      "Epoch 9. Loss 0.4791. accuracy 0.7500. Elapsed 69 seconds\n",
      "Epoch 9. Loss 0.4793. accuracy 0.7500. Elapsed 69 seconds\n",
      "Epoch 9. Loss 0.4782. accuracy 0.7500. Elapsed 69 seconds\n",
      "Epoch 9. Loss 0.4762. accuracy 0.7500. Elapsed 69 seconds\n",
      "Epoch 9. Loss 0.4757. accuracy 0.7500. Elapsed 70 seconds\n",
      "Epoch 9. Loss 0.4766. accuracy 0.7500. Elapsed 70 seconds\n",
      "Epoch 9. Loss 0.4776. accuracy 0.7500. Elapsed 70 seconds\n",
      "Epoch 9. Loss 0.4772. accuracy 0.7500. Elapsed 71 seconds\n",
      "Epoch 9. Loss 0.4760. accuracy 0.7500. Elapsed 71 seconds\n",
      "Epoch 9. Loss 0.4767. accuracy 0.7500. Elapsed 71 seconds\n",
      "Epoch 9. Loss 0.4780. accuracy 0.7500. Elapsed 71 seconds\n",
      "Epoch 9. Loss 0.4795. accuracy 0.7500. Elapsed 72 seconds\n",
      "Epoch 9. Loss 0.4801. accuracy 0.7500. Elapsed 72 seconds\n",
      "Epoch 9. Loss 0.4817. accuracy 0.7447. Elapsed 72 seconds\n",
      "Epoch 9. Loss 0.4820. accuracy 0.7500. Elapsed 73 seconds\n",
      "Epoch 9. Loss 0.4804. accuracy 0.7447. Elapsed 73 seconds\n",
      "Epoch 9. Loss 0.4797. accuracy 0.7500. Elapsed 73 seconds\n",
      "Epoch 9. Loss 0.4774. accuracy 0.7500. Elapsed 74 seconds\n",
      "ep acc 0.7495622099641013\n",
      "Epoch 10. Loss 0.4898. accuracy 0.7500. Elapsed 74 seconds\n",
      "Epoch 10. Loss 0.5041. accuracy 0.7500. Elapsed 74 seconds\n",
      "Epoch 10. Loss 0.4922. accuracy 0.7500. Elapsed 75 seconds\n",
      "Epoch 10. Loss 0.4767. accuracy 0.7500. Elapsed 75 seconds\n",
      "Epoch 10. Loss 0.4738. accuracy 0.7500. Elapsed 75 seconds\n",
      "Epoch 10. Loss 0.4810. accuracy 0.7500. Elapsed 76 seconds\n",
      "Epoch 10. Loss 0.4728. accuracy 0.7500. Elapsed 76 seconds\n",
      "Epoch 10. Loss 0.4728. accuracy 0.7500. Elapsed 76 seconds\n",
      "Epoch 10. Loss 0.4764. accuracy 0.7500. Elapsed 77 seconds\n",
      "Epoch 10. Loss 0.4767. accuracy 0.7447. Elapsed 77 seconds\n",
      "Epoch 10. Loss 0.4758. accuracy 0.7447. Elapsed 77 seconds\n",
      "Epoch 10. Loss 0.4754. accuracy 0.7447. Elapsed 78 seconds\n",
      "Epoch 10. Loss 0.4729. accuracy 0.7447. Elapsed 78 seconds\n",
      "Epoch 10. Loss 0.4731. accuracy 0.7447. Elapsed 78 seconds\n",
      "Epoch 10. Loss 0.4745. accuracy 0.7447. Elapsed 78 seconds\n",
      "Epoch 10. Loss 0.4762. accuracy 0.7447. Elapsed 79 seconds\n",
      "Epoch 10. Loss 0.4763. accuracy 0.7340. Elapsed 79 seconds\n",
      "Epoch 10. Loss 0.4749. accuracy 0.7394. Elapsed 79 seconds\n",
      "Epoch 10. Loss 0.4743. accuracy 0.7394. Elapsed 80 seconds\n",
      "Epoch 10. Loss 0.4746. accuracy 0.7394. Elapsed 80 seconds\n",
      "Epoch 10. Loss 0.4750. accuracy 0.7394. Elapsed 80 seconds\n",
      "Epoch 10. Loss 0.4756. accuracy 0.7447. Elapsed 81 seconds\n",
      "Epoch 10. Loss 0.4751. accuracy 0.7340. Elapsed 81 seconds\n",
      "Epoch 10. Loss 0.4717. accuracy 0.7394. Elapsed 81 seconds\n",
      "Epoch 10. Loss 0.4733. accuracy 0.7447. Elapsed 81 seconds\n",
      "Epoch 10. Loss 0.4731. accuracy 0.7500. Elapsed 82 seconds\n",
      "Epoch 10. Loss 0.4735. accuracy 0.7394. Elapsed 82 seconds\n",
      "ep acc 0.7490740740740741\n",
      "Epoch 11. Loss 0.4573. accuracy 0.7394. Elapsed 82 seconds\n",
      "Epoch 11. Loss 0.4552. accuracy 0.7447. Elapsed 83 seconds\n",
      "Epoch 11. Loss 0.4548. accuracy 0.7394. Elapsed 83 seconds\n",
      "Epoch 11. Loss 0.4622. accuracy 0.7394. Elapsed 83 seconds\n",
      "Epoch 11. Loss 0.4577. accuracy 0.7447. Elapsed 84 seconds\n",
      "Epoch 11. Loss 0.4578. accuracy 0.7447. Elapsed 84 seconds\n",
      "Epoch 11. Loss 0.4491. accuracy 0.7447. Elapsed 84 seconds\n",
      "Epoch 11. Loss 0.4536. accuracy 0.7394. Elapsed 85 seconds\n",
      "Epoch 11. Loss 0.4589. accuracy 0.7394. Elapsed 85 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11. Loss 0.4558. accuracy 0.7394. Elapsed 85 seconds\n",
      "Epoch 11. Loss 0.4592. accuracy 0.7394. Elapsed 85 seconds\n",
      "Epoch 11. Loss 0.4612. accuracy 0.7394. Elapsed 86 seconds\n",
      "Epoch 11. Loss 0.4614. accuracy 0.7447. Elapsed 86 seconds\n",
      "Epoch 11. Loss 0.4612. accuracy 0.7447. Elapsed 86 seconds\n",
      "Epoch 11. Loss 0.4601. accuracy 0.7394. Elapsed 87 seconds\n",
      "Epoch 11. Loss 0.4595. accuracy 0.7447. Elapsed 87 seconds\n",
      "Epoch 11. Loss 0.4640. accuracy 0.7447. Elapsed 87 seconds\n",
      "Epoch 11. Loss 0.4638. accuracy 0.7394. Elapsed 88 seconds\n",
      "Epoch 11. Loss 0.4639. accuracy 0.7394. Elapsed 88 seconds\n",
      "Epoch 11. Loss 0.4657. accuracy 0.7394. Elapsed 88 seconds\n",
      "Epoch 11. Loss 0.4670. accuracy 0.7394. Elapsed 89 seconds\n",
      "Epoch 11. Loss 0.4685. accuracy 0.7394. Elapsed 89 seconds\n",
      "Epoch 11. Loss 0.4682. accuracy 0.7394. Elapsed 89 seconds\n",
      "Epoch 11. Loss 0.4669. accuracy 0.7394. Elapsed 90 seconds\n",
      "Epoch 11. Loss 0.4689. accuracy 0.7394. Elapsed 90 seconds\n",
      "Epoch 11. Loss 0.4698. accuracy 0.7394. Elapsed 90 seconds\n",
      "Epoch 11. Loss 0.4684. accuracy 0.7394. Elapsed 91 seconds\n",
      "ep acc 0.748334407908876\n",
      "Epoch 12. Loss 0.4877. accuracy 0.7394. Elapsed 91 seconds\n",
      "Epoch 12. Loss 0.4757. accuracy 0.7394. Elapsed 91 seconds\n",
      "Epoch 12. Loss 0.4869. accuracy 0.7394. Elapsed 91 seconds\n",
      "Epoch 12. Loss 0.4806. accuracy 0.7394. Elapsed 92 seconds\n",
      "Epoch 12. Loss 0.4719. accuracy 0.7394. Elapsed 92 seconds\n",
      "Epoch 12. Loss 0.4708. accuracy 0.7340. Elapsed 92 seconds\n",
      "Epoch 12. Loss 0.4666. accuracy 0.7394. Elapsed 93 seconds\n",
      "Epoch 12. Loss 0.4703. accuracy 0.7394. Elapsed 93 seconds\n",
      "Epoch 12. Loss 0.4729. accuracy 0.7394. Elapsed 93 seconds\n",
      "Epoch 12. Loss 0.4704. accuracy 0.7394. Elapsed 94 seconds\n",
      "Epoch 12. Loss 0.4744. accuracy 0.7340. Elapsed 94 seconds\n",
      "Epoch 12. Loss 0.4689. accuracy 0.7340. Elapsed 94 seconds\n",
      "Epoch 12. Loss 0.4658. accuracy 0.7340. Elapsed 95 seconds\n",
      "Epoch 12. Loss 0.4648. accuracy 0.7394. Elapsed 95 seconds\n",
      "Epoch 12. Loss 0.4666. accuracy 0.7340. Elapsed 95 seconds\n",
      "Epoch 12. Loss 0.4671. accuracy 0.7234. Elapsed 95 seconds\n",
      "Epoch 12. Loss 0.4667. accuracy 0.7394. Elapsed 96 seconds\n",
      "Epoch 12. Loss 0.4682. accuracy 0.7340. Elapsed 96 seconds\n",
      "Epoch 12. Loss 0.4681. accuracy 0.7234. Elapsed 96 seconds\n",
      "Epoch 12. Loss 0.4655. accuracy 0.7181. Elapsed 97 seconds\n",
      "Epoch 12. Loss 0.4659. accuracy 0.7340. Elapsed 97 seconds\n",
      "Epoch 12. Loss 0.4648. accuracy 0.7287. Elapsed 97 seconds\n",
      "Epoch 12. Loss 0.4650. accuracy 0.7394. Elapsed 98 seconds\n",
      "Epoch 12. Loss 0.4665. accuracy 0.7394. Elapsed 98 seconds\n",
      "Epoch 12. Loss 0.4650. accuracy 0.7394. Elapsed 99 seconds\n",
      "Epoch 12. Loss 0.4668. accuracy 0.7287. Elapsed 99 seconds\n",
      "Epoch 12. Loss 0.4639. accuracy 0.7340. Elapsed 99 seconds\n",
      "ep acc 0.7472255056474915\n",
      "Epoch 13. Loss 0.4487. accuracy 0.7394. Elapsed 100 seconds\n",
      "Epoch 13. Loss 0.4439. accuracy 0.7394. Elapsed 100 seconds\n",
      "Epoch 13. Loss 0.4660. accuracy 0.7394. Elapsed 100 seconds\n",
      "Epoch 13. Loss 0.4698. accuracy 0.7394. Elapsed 101 seconds\n",
      "Epoch 13. Loss 0.4713. accuracy 0.7340. Elapsed 101 seconds\n",
      "Epoch 13. Loss 0.4669. accuracy 0.7340. Elapsed 102 seconds\n",
      "Epoch 13. Loss 0.4602. accuracy 0.7340. Elapsed 102 seconds\n",
      "Epoch 13. Loss 0.4665. accuracy 0.7394. Elapsed 102 seconds\n",
      "Epoch 13. Loss 0.4652. accuracy 0.7340. Elapsed 103 seconds\n",
      "Epoch 13. Loss 0.4617. accuracy 0.7340. Elapsed 103 seconds\n",
      "Epoch 13. Loss 0.4597. accuracy 0.7234. Elapsed 104 seconds\n",
      "Epoch 13. Loss 0.4634. accuracy 0.7394. Elapsed 104 seconds\n",
      "Epoch 13. Loss 0.4629. accuracy 0.7340. Elapsed 104 seconds\n",
      "Epoch 13. Loss 0.4656. accuracy 0.7394. Elapsed 105 seconds\n",
      "Epoch 13. Loss 0.4616. accuracy 0.7394. Elapsed 105 seconds\n",
      "Epoch 13. Loss 0.4607. accuracy 0.7340. Elapsed 105 seconds\n",
      "Epoch 13. Loss 0.4593. accuracy 0.7340. Elapsed 106 seconds\n",
      "Epoch 13. Loss 0.4616. accuracy 0.7287. Elapsed 106 seconds\n",
      "Epoch 13. Loss 0.4605. accuracy 0.7287. Elapsed 107 seconds\n",
      "Epoch 13. Loss 0.4601. accuracy 0.7340. Elapsed 107 seconds\n",
      "Epoch 13. Loss 0.4601. accuracy 0.7394. Elapsed 107 seconds\n",
      "Epoch 13. Loss 0.4593. accuracy 0.7287. Elapsed 108 seconds\n",
      "Epoch 13. Loss 0.4588. accuracy 0.7394. Elapsed 108 seconds\n",
      "Epoch 13. Loss 0.4591. accuracy 0.7394. Elapsed 108 seconds\n",
      "Epoch 13. Loss 0.4614. accuracy 0.7340. Elapsed 109 seconds\n",
      "Epoch 13. Loss 0.4607. accuracy 0.7394. Elapsed 109 seconds\n",
      "Epoch 13. Loss 0.4603. accuracy 0.7340. Elapsed 109 seconds\n",
      "ep acc 0.746317512274959\n",
      "Epoch 14. Loss 0.4669. accuracy 0.7394. Elapsed 110 seconds\n",
      "Epoch 14. Loss 0.4772. accuracy 0.7394. Elapsed 110 seconds\n",
      "Epoch 14. Loss 0.4570. accuracy 0.7394. Elapsed 110 seconds\n",
      "Epoch 14. Loss 0.4678. accuracy 0.7340. Elapsed 110 seconds\n",
      "Epoch 14. Loss 0.4605. accuracy 0.7394. Elapsed 110 seconds\n",
      "Epoch 14. Loss 0.4569. accuracy 0.7394. Elapsed 111 seconds\n",
      "Epoch 14. Loss 0.4579. accuracy 0.7394. Elapsed 111 seconds\n",
      "Epoch 14. Loss 0.4534. accuracy 0.7394. Elapsed 111 seconds\n",
      "Epoch 14. Loss 0.4495. accuracy 0.7394. Elapsed 112 seconds\n",
      "Epoch 14. Loss 0.4495. accuracy 0.7394. Elapsed 112 seconds\n",
      "Epoch 14. Loss 0.4489. accuracy 0.7394. Elapsed 112 seconds\n",
      "Epoch 14. Loss 0.4496. accuracy 0.7340. Elapsed 112 seconds\n",
      "Epoch 14. Loss 0.4488. accuracy 0.7340. Elapsed 113 seconds\n",
      "Epoch 14. Loss 0.4479. accuracy 0.7340. Elapsed 113 seconds\n",
      "Epoch 14. Loss 0.4437. accuracy 0.7287. Elapsed 113 seconds\n",
      "Epoch 14. Loss 0.4453. accuracy 0.7234. Elapsed 113 seconds\n",
      "Epoch 14. Loss 0.4432. accuracy 0.7181. Elapsed 114 seconds\n",
      "Epoch 14. Loss 0.4482. accuracy 0.7340. Elapsed 114 seconds\n",
      "Epoch 14. Loss 0.4510. accuracy 0.7340. Elapsed 114 seconds\n",
      "Epoch 14. Loss 0.4492. accuracy 0.7287. Elapsed 114 seconds\n",
      "Epoch 14. Loss 0.4509. accuracy 0.7340. Elapsed 115 seconds\n",
      "Epoch 14. Loss 0.4526. accuracy 0.7234. Elapsed 115 seconds\n",
      "Epoch 14. Loss 0.4537. accuracy 0.7340. Elapsed 115 seconds\n",
      "Epoch 14. Loss 0.4561. accuracy 0.7340. Elapsed 115 seconds\n",
      "Epoch 14. Loss 0.4567. accuracy 0.7340. Elapsed 116 seconds\n",
      "Epoch 14. Loss 0.4553. accuracy 0.7340. Elapsed 116 seconds\n",
      "Epoch 14. Loss 0.4539. accuracy 0.7340. Elapsed 116 seconds\n",
      "ep acc 0.7454548013058651\n",
      "Epoch 15. Loss 0.4530. accuracy 0.7340. Elapsed 116 seconds\n",
      "Epoch 15. Loss 0.4597. accuracy 0.7340. Elapsed 117 seconds\n",
      "Epoch 15. Loss 0.4563. accuracy 0.7287. Elapsed 117 seconds\n",
      "Epoch 15. Loss 0.4629. accuracy 0.7394. Elapsed 117 seconds\n",
      "Epoch 15. Loss 0.4647. accuracy 0.7287. Elapsed 118 seconds\n",
      "Epoch 15. Loss 0.4530. accuracy 0.7287. Elapsed 118 seconds\n",
      "Epoch 15. Loss 0.4536. accuracy 0.7287. Elapsed 118 seconds\n",
      "Epoch 15. Loss 0.4586. accuracy 0.7287. Elapsed 118 seconds\n",
      "Epoch 15. Loss 0.4566. accuracy 0.7394. Elapsed 119 seconds\n",
      "Epoch 15. Loss 0.4546. accuracy 0.7394. Elapsed 119 seconds\n",
      "Epoch 15. Loss 0.4502. accuracy 0.7340. Elapsed 119 seconds\n",
      "Epoch 15. Loss 0.4553. accuracy 0.7287. Elapsed 119 seconds\n",
      "Epoch 15. Loss 0.4549. accuracy 0.7287. Elapsed 120 seconds\n",
      "Epoch 15. Loss 0.4544. accuracy 0.7287. Elapsed 120 seconds\n",
      "Epoch 15. Loss 0.4548. accuracy 0.7287. Elapsed 120 seconds\n",
      "Epoch 15. Loss 0.4547. accuracy 0.7287. Elapsed 120 seconds\n",
      "Epoch 15. Loss 0.4563. accuracy 0.7287. Elapsed 121 seconds\n",
      "Epoch 15. Loss 0.4539. accuracy 0.7287. Elapsed 121 seconds\n",
      "Epoch 15. Loss 0.4527. accuracy 0.7287. Elapsed 121 seconds\n",
      "Epoch 15. Loss 0.4510. accuracy 0.7340. Elapsed 122 seconds\n",
      "Epoch 15. Loss 0.4532. accuracy 0.7287. Elapsed 122 seconds\n",
      "Epoch 15. Loss 0.4555. accuracy 0.7287. Elapsed 122 seconds\n",
      "Epoch 15. Loss 0.4561. accuracy 0.7287. Elapsed 122 seconds\n",
      "Epoch 15. Loss 0.4554. accuracy 0.7287. Elapsed 123 seconds\n",
      "Epoch 15. Loss 0.4546. accuracy 0.7340. Elapsed 123 seconds\n",
      "Epoch 15. Loss 0.4533. accuracy 0.7340. Elapsed 123 seconds\n",
      "Epoch 15. Loss 0.4508. accuracy 0.7340. Elapsed 123 seconds\n",
      "ep acc 0.7445101129498294\n",
      "Epoch 16. Loss 0.4889. accuracy 0.7340. Elapsed 124 seconds\n",
      "Epoch 16. Loss 0.4883. accuracy 0.7340. Elapsed 124 seconds\n",
      "Epoch 16. Loss 0.4745. accuracy 0.7287. Elapsed 124 seconds\n",
      "Epoch 16. Loss 0.4624. accuracy 0.7287. Elapsed 124 seconds\n",
      "Epoch 16. Loss 0.4623. accuracy 0.7287. Elapsed 125 seconds\n",
      "Epoch 16. Loss 0.4609. accuracy 0.7234. Elapsed 125 seconds\n",
      "Epoch 16. Loss 0.4593. accuracy 0.7394. Elapsed 125 seconds\n",
      "Epoch 16. Loss 0.4613. accuracy 0.7340. Elapsed 126 seconds\n",
      "Epoch 16. Loss 0.4646. accuracy 0.7340. Elapsed 126 seconds\n",
      "Epoch 16. Loss 0.4621. accuracy 0.7340. Elapsed 126 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16. Loss 0.4559. accuracy 0.7340. Elapsed 127 seconds\n",
      "Epoch 16. Loss 0.4584. accuracy 0.7340. Elapsed 127 seconds\n",
      "Epoch 16. Loss 0.4564. accuracy 0.7394. Elapsed 127 seconds\n",
      "Epoch 16. Loss 0.4558. accuracy 0.7340. Elapsed 128 seconds\n",
      "Epoch 16. Loss 0.4545. accuracy 0.7340. Elapsed 128 seconds\n",
      "Epoch 16. Loss 0.4522. accuracy 0.7340. Elapsed 129 seconds\n",
      "Epoch 16. Loss 0.4490. accuracy 0.7287. Elapsed 130 seconds\n",
      "Epoch 16. Loss 0.4487. accuracy 0.7287. Elapsed 130 seconds\n",
      "Epoch 16. Loss 0.4484. accuracy 0.7287. Elapsed 130 seconds\n",
      "Epoch 16. Loss 0.4480. accuracy 0.7340. Elapsed 131 seconds\n",
      "Epoch 16. Loss 0.4481. accuracy 0.7287. Elapsed 131 seconds\n",
      "Epoch 16. Loss 0.4490. accuracy 0.7287. Elapsed 132 seconds\n",
      "Epoch 16. Loss 0.4493. accuracy 0.7287. Elapsed 132 seconds\n",
      "Epoch 16. Loss 0.4473. accuracy 0.7287. Elapsed 132 seconds\n",
      "Epoch 16. Loss 0.4487. accuracy 0.7287. Elapsed 133 seconds\n",
      "Epoch 16. Loss 0.4461. accuracy 0.7287. Elapsed 133 seconds\n",
      "Epoch 16. Loss 0.4447. accuracy 0.7394. Elapsed 134 seconds\n",
      "ep acc 0.743720449172577\n",
      "Epoch 17. Loss 0.4110. accuracy 0.7287. Elapsed 134 seconds\n",
      "Epoch 17. Loss 0.4333. accuracy 0.7287. Elapsed 134 seconds\n",
      "Epoch 17. Loss 0.4509. accuracy 0.7340. Elapsed 135 seconds\n",
      "Epoch 17. Loss 0.4338. accuracy 0.7340. Elapsed 135 seconds\n",
      "Epoch 17. Loss 0.4387. accuracy 0.7287. Elapsed 135 seconds\n",
      "Epoch 17. Loss 0.4462. accuracy 0.7340. Elapsed 136 seconds\n",
      "Epoch 17. Loss 0.4447. accuracy 0.7287. Elapsed 136 seconds\n",
      "Epoch 17. Loss 0.4428. accuracy 0.7340. Elapsed 136 seconds\n",
      "Epoch 17. Loss 0.4496. accuracy 0.7340. Elapsed 137 seconds\n",
      "Epoch 17. Loss 0.4480. accuracy 0.7340. Elapsed 137 seconds\n",
      "Epoch 17. Loss 0.4479. accuracy 0.7340. Elapsed 137 seconds\n",
      "Epoch 17. Loss 0.4426. accuracy 0.7340. Elapsed 138 seconds\n",
      "Epoch 17. Loss 0.4418. accuracy 0.7340. Elapsed 138 seconds\n",
      "Epoch 17. Loss 0.4409. accuracy 0.7287. Elapsed 138 seconds\n",
      "Epoch 17. Loss 0.4387. accuracy 0.7394. Elapsed 139 seconds\n",
      "Epoch 17. Loss 0.4401. accuracy 0.7340. Elapsed 139 seconds\n",
      "Epoch 17. Loss 0.4438. accuracy 0.7340. Elapsed 139 seconds\n",
      "Epoch 17. Loss 0.4425. accuracy 0.7394. Elapsed 140 seconds\n",
      "Epoch 17. Loss 0.4405. accuracy 0.7340. Elapsed 140 seconds\n",
      "Epoch 17. Loss 0.4391. accuracy 0.7394. Elapsed 140 seconds\n",
      "Epoch 17. Loss 0.4355. accuracy 0.7394. Elapsed 141 seconds\n",
      "Epoch 17. Loss 0.4352. accuracy 0.7394. Elapsed 141 seconds\n",
      "Epoch 17. Loss 0.4367. accuracy 0.7394. Elapsed 141 seconds\n",
      "Epoch 17. Loss 0.4387. accuracy 0.7340. Elapsed 141 seconds\n",
      "Epoch 17. Loss 0.4410. accuracy 0.7287. Elapsed 142 seconds\n",
      "Epoch 17. Loss 0.4408. accuracy 0.7340. Elapsed 142 seconds\n",
      "Epoch 17. Loss 0.4413. accuracy 0.7394. Elapsed 142 seconds\n",
      "ep acc 0.7431627497334632\n",
      "Epoch 18. Loss 0.4627. accuracy 0.7287. Elapsed 142 seconds\n",
      "Epoch 18. Loss 0.4478. accuracy 0.7287. Elapsed 143 seconds\n",
      "Epoch 18. Loss 0.4448. accuracy 0.7287. Elapsed 143 seconds\n",
      "Epoch 18. Loss 0.4412. accuracy 0.7234. Elapsed 143 seconds\n",
      "Epoch 18. Loss 0.4424. accuracy 0.7340. Elapsed 143 seconds\n",
      "Epoch 18. Loss 0.4319. accuracy 0.7340. Elapsed 144 seconds\n",
      "Epoch 18. Loss 0.4320. accuracy 0.7340. Elapsed 144 seconds\n",
      "Epoch 18. Loss 0.4272. accuracy 0.7340. Elapsed 144 seconds\n",
      "Epoch 18. Loss 0.4312. accuracy 0.7287. Elapsed 145 seconds\n",
      "Epoch 18. Loss 0.4300. accuracy 0.7287. Elapsed 145 seconds\n",
      "Epoch 18. Loss 0.4358. accuracy 0.7340. Elapsed 145 seconds\n",
      "Epoch 18. Loss 0.4322. accuracy 0.7287. Elapsed 145 seconds\n",
      "Epoch 18. Loss 0.4310. accuracy 0.7234. Elapsed 146 seconds\n",
      "Epoch 18. Loss 0.4301. accuracy 0.7234. Elapsed 146 seconds\n",
      "Epoch 18. Loss 0.4339. accuracy 0.7340. Elapsed 146 seconds\n",
      "Epoch 18. Loss 0.4333. accuracy 0.7287. Elapsed 147 seconds\n",
      "Epoch 18. Loss 0.4322. accuracy 0.7287. Elapsed 147 seconds\n",
      "Epoch 18. Loss 0.4349. accuracy 0.7340. Elapsed 147 seconds\n",
      "Epoch 18. Loss 0.4369. accuracy 0.7340. Elapsed 148 seconds\n",
      "Epoch 18. Loss 0.4364. accuracy 0.7340. Elapsed 148 seconds\n",
      "Epoch 18. Loss 0.4376. accuracy 0.7340. Elapsed 148 seconds\n",
      "Epoch 18. Loss 0.4360. accuracy 0.7340. Elapsed 149 seconds\n",
      "Epoch 18. Loss 0.4350. accuracy 0.7340. Elapsed 149 seconds\n",
      "Epoch 18. Loss 0.4365. accuracy 0.7287. Elapsed 150 seconds\n",
      "Epoch 18. Loss 0.4377. accuracy 0.7340. Elapsed 150 seconds\n",
      "Epoch 18. Loss 0.4395. accuracy 0.7287. Elapsed 151 seconds\n",
      "Epoch 18. Loss 0.4395. accuracy 0.7234. Elapsed 151 seconds\n",
      "ep acc 0.7424590666316436\n",
      "Epoch 19. Loss 0.4303. accuracy 0.7234. Elapsed 151 seconds\n",
      "Epoch 19. Loss 0.4395. accuracy 0.7287. Elapsed 152 seconds\n",
      "Epoch 19. Loss 0.4340. accuracy 0.7181. Elapsed 152 seconds\n",
      "Epoch 19. Loss 0.4260. accuracy 0.7234. Elapsed 152 seconds\n",
      "Epoch 19. Loss 0.4322. accuracy 0.7234. Elapsed 153 seconds\n",
      "Epoch 19. Loss 0.4344. accuracy 0.7234. Elapsed 153 seconds\n",
      "Epoch 19. Loss 0.4405. accuracy 0.7234. Elapsed 153 seconds\n",
      "Epoch 19. Loss 0.4385. accuracy 0.7234. Elapsed 154 seconds\n",
      "Epoch 19. Loss 0.4329. accuracy 0.7234. Elapsed 154 seconds\n",
      "Epoch 19. Loss 0.4300. accuracy 0.7287. Elapsed 154 seconds\n",
      "Epoch 19. Loss 0.4329. accuracy 0.7181. Elapsed 155 seconds\n",
      "Epoch 19. Loss 0.4370. accuracy 0.7181. Elapsed 155 seconds\n",
      "Epoch 19. Loss 0.4384. accuracy 0.7181. Elapsed 155 seconds\n",
      "Epoch 19. Loss 0.4369. accuracy 0.7234. Elapsed 156 seconds\n",
      "Epoch 19. Loss 0.4389. accuracy 0.7287. Elapsed 156 seconds\n",
      "Epoch 19. Loss 0.4359. accuracy 0.7287. Elapsed 156 seconds\n",
      "Epoch 19. Loss 0.4355. accuracy 0.7287. Elapsed 157 seconds\n",
      "Epoch 19. Loss 0.4330. accuracy 0.7287. Elapsed 157 seconds\n",
      "Epoch 19. Loss 0.4369. accuracy 0.7340. Elapsed 157 seconds\n",
      "Epoch 19. Loss 0.4344. accuracy 0.7287. Elapsed 158 seconds\n",
      "Epoch 19. Loss 0.4336. accuracy 0.7287. Elapsed 158 seconds\n",
      "Epoch 19. Loss 0.4341. accuracy 0.7287. Elapsed 158 seconds\n",
      "Epoch 19. Loss 0.4339. accuracy 0.7287. Elapsed 158 seconds\n",
      "Epoch 19. Loss 0.4337. accuracy 0.7287. Elapsed 159 seconds\n",
      "Epoch 19. Loss 0.4351. accuracy 0.7340. Elapsed 159 seconds\n",
      "Epoch 19. Loss 0.4352. accuracy 0.7287. Elapsed 159 seconds\n",
      "Epoch 19. Loss 0.4325. accuracy 0.7181. Elapsed 160 seconds\n",
      "ep acc 0.7415702376508648\n",
      "Epoch 20. Loss 0.4590. accuracy 0.7340. Elapsed 160 seconds\n",
      "Epoch 20. Loss 0.4413. accuracy 0.7234. Elapsed 160 seconds\n",
      "Epoch 20. Loss 0.4413. accuracy 0.7287. Elapsed 160 seconds\n",
      "Epoch 20. Loss 0.4349. accuracy 0.7287. Elapsed 161 seconds\n",
      "Epoch 20. Loss 0.4266. accuracy 0.7340. Elapsed 161 seconds\n",
      "Epoch 20. Loss 0.4287. accuracy 0.7234. Elapsed 161 seconds\n",
      "Epoch 20. Loss 0.4275. accuracy 0.7287. Elapsed 161 seconds\n",
      "Epoch 20. Loss 0.4249. accuracy 0.7287. Elapsed 162 seconds\n",
      "Epoch 20. Loss 0.4232. accuracy 0.7234. Elapsed 162 seconds\n",
      "Epoch 20. Loss 0.4274. accuracy 0.7287. Elapsed 162 seconds\n",
      "Epoch 20. Loss 0.4286. accuracy 0.7234. Elapsed 163 seconds\n",
      "Epoch 20. Loss 0.4245. accuracy 0.7181. Elapsed 163 seconds\n",
      "Epoch 20. Loss 0.4258. accuracy 0.7287. Elapsed 163 seconds\n",
      "Epoch 20. Loss 0.4249. accuracy 0.7287. Elapsed 163 seconds\n",
      "Epoch 20. Loss 0.4268. accuracy 0.7287. Elapsed 164 seconds\n",
      "Epoch 20. Loss 0.4253. accuracy 0.7287. Elapsed 164 seconds\n",
      "Epoch 20. Loss 0.4250. accuracy 0.7287. Elapsed 164 seconds\n",
      "Epoch 20. Loss 0.4265. accuracy 0.7287. Elapsed 164 seconds\n",
      "Epoch 20. Loss 0.4283. accuracy 0.7287. Elapsed 165 seconds\n",
      "Epoch 20. Loss 0.4278. accuracy 0.7234. Elapsed 165 seconds\n",
      "Epoch 20. Loss 0.4302. accuracy 0.7287. Elapsed 165 seconds\n",
      "Epoch 20. Loss 0.4308. accuracy 0.7181. Elapsed 166 seconds\n",
      "Epoch 20. Loss 0.4302. accuracy 0.7234. Elapsed 166 seconds\n",
      "Epoch 20. Loss 0.4273. accuracy 0.7234. Elapsed 166 seconds\n",
      "Epoch 20. Loss 0.4285. accuracy 0.7128. Elapsed 166 seconds\n",
      "Epoch 20. Loss 0.4288. accuracy 0.7128. Elapsed 167 seconds\n",
      "Epoch 20. Loss 0.4270. accuracy 0.7181. Elapsed 167 seconds\n",
      "ep acc 0.7407604412923563\n",
      "Epoch 21. Loss 0.4017. accuracy 0.7234. Elapsed 167 seconds\n",
      "Epoch 21. Loss 0.4052. accuracy 0.7234. Elapsed 168 seconds\n",
      "Epoch 21. Loss 0.4136. accuracy 0.7287. Elapsed 168 seconds\n",
      "Epoch 21. Loss 0.4154. accuracy 0.7287. Elapsed 168 seconds\n",
      "Epoch 21. Loss 0.4227. accuracy 0.7181. Elapsed 169 seconds\n",
      "Epoch 21. Loss 0.4173. accuracy 0.7287. Elapsed 169 seconds\n",
      "Epoch 21. Loss 0.4230. accuracy 0.7287. Elapsed 169 seconds\n",
      "Epoch 21. Loss 0.4225. accuracy 0.7287. Elapsed 169 seconds\n",
      "Epoch 21. Loss 0.4266. accuracy 0.7287. Elapsed 170 seconds\n",
      "Epoch 21. Loss 0.4244. accuracy 0.7287. Elapsed 170 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21. Loss 0.4199. accuracy 0.7287. Elapsed 170 seconds\n",
      "Epoch 21. Loss 0.4231. accuracy 0.7287. Elapsed 170 seconds\n",
      "Epoch 21. Loss 0.4209. accuracy 0.7287. Elapsed 171 seconds\n",
      "Epoch 21. Loss 0.4197. accuracy 0.7287. Elapsed 171 seconds\n",
      "Epoch 21. Loss 0.4182. accuracy 0.7287. Elapsed 171 seconds\n",
      "Epoch 21. Loss 0.4173. accuracy 0.7340. Elapsed 172 seconds\n",
      "Epoch 21. Loss 0.4179. accuracy 0.7394. Elapsed 172 seconds\n",
      "Epoch 21. Loss 0.4171. accuracy 0.7234. Elapsed 172 seconds\n",
      "Epoch 21. Loss 0.4160. accuracy 0.7287. Elapsed 173 seconds\n",
      "Epoch 21. Loss 0.4191. accuracy 0.7234. Elapsed 173 seconds\n",
      "Epoch 21. Loss 0.4209. accuracy 0.7287. Elapsed 173 seconds\n",
      "Epoch 21. Loss 0.4200. accuracy 0.7340. Elapsed 173 seconds\n",
      "Epoch 21. Loss 0.4211. accuracy 0.7287. Elapsed 174 seconds\n",
      "Epoch 21. Loss 0.4219. accuracy 0.7234. Elapsed 174 seconds\n",
      "Epoch 21. Loss 0.4236. accuracy 0.7234. Elapsed 174 seconds\n",
      "Epoch 21. Loss 0.4224. accuracy 0.7234. Elapsed 175 seconds\n",
      "Epoch 21. Loss 0.4243. accuracy 0.7074. Elapsed 175 seconds\n",
      "ep acc 0.7401028181170025\n",
      "Epoch 22. Loss 0.4220. accuracy 0.7128. Elapsed 175 seconds\n",
      "Epoch 22. Loss 0.4563. accuracy 0.7181. Elapsed 176 seconds\n",
      "Epoch 22. Loss 0.4555. accuracy 0.7181. Elapsed 176 seconds\n",
      "Epoch 22. Loss 0.4306. accuracy 0.7234. Elapsed 176 seconds\n",
      "Epoch 22. Loss 0.4268. accuracy 0.7287. Elapsed 177 seconds\n",
      "Epoch 22. Loss 0.4272. accuracy 0.7181. Elapsed 177 seconds\n",
      "Epoch 22. Loss 0.4310. accuracy 0.7181. Elapsed 177 seconds\n",
      "Epoch 22. Loss 0.4217. accuracy 0.7234. Elapsed 177 seconds\n",
      "Epoch 22. Loss 0.4172. accuracy 0.7234. Elapsed 178 seconds\n",
      "Epoch 22. Loss 0.4187. accuracy 0.7234. Elapsed 178 seconds\n",
      "Epoch 22. Loss 0.4173. accuracy 0.7287. Elapsed 178 seconds\n",
      "Epoch 22. Loss 0.4159. accuracy 0.7287. Elapsed 179 seconds\n",
      "Epoch 22. Loss 0.4105. accuracy 0.7181. Elapsed 179 seconds\n",
      "Epoch 22. Loss 0.4107. accuracy 0.7340. Elapsed 179 seconds\n",
      "Epoch 22. Loss 0.4097. accuracy 0.7181. Elapsed 180 seconds\n",
      "Epoch 22. Loss 0.4128. accuracy 0.7234. Elapsed 180 seconds\n",
      "Epoch 22. Loss 0.4111. accuracy 0.7234. Elapsed 180 seconds\n",
      "Epoch 22. Loss 0.4142. accuracy 0.7234. Elapsed 181 seconds\n",
      "Epoch 22. Loss 0.4161. accuracy 0.7287. Elapsed 181 seconds\n",
      "Epoch 22. Loss 0.4170. accuracy 0.7181. Elapsed 181 seconds\n",
      "Epoch 22. Loss 0.4173. accuracy 0.7287. Elapsed 181 seconds\n",
      "Epoch 22. Loss 0.4169. accuracy 0.7234. Elapsed 182 seconds\n",
      "Epoch 22. Loss 0.4160. accuracy 0.7287. Elapsed 182 seconds\n",
      "Epoch 22. Loss 0.4170. accuracy 0.7234. Elapsed 182 seconds\n",
      "Epoch 22. Loss 0.4181. accuracy 0.7074. Elapsed 183 seconds\n",
      "Epoch 22. Loss 0.4184. accuracy 0.7287. Elapsed 183 seconds\n",
      "Epoch 22. Loss 0.4206. accuracy 0.7181. Elapsed 183 seconds\n",
      "ep acc 0.7393079733505266\n",
      "Epoch 23. Loss 0.3707. accuracy 0.7181. Elapsed 184 seconds\n",
      "Epoch 23. Loss 0.3853. accuracy 0.7287. Elapsed 184 seconds\n",
      "Epoch 23. Loss 0.3849. accuracy 0.7234. Elapsed 184 seconds\n",
      "Epoch 23. Loss 0.3992. accuracy 0.7181. Elapsed 185 seconds\n",
      "Epoch 23. Loss 0.3853. accuracy 0.7234. Elapsed 185 seconds\n",
      "Epoch 23. Loss 0.3831. accuracy 0.7181. Elapsed 185 seconds\n",
      "Epoch 23. Loss 0.3829. accuracy 0.7287. Elapsed 186 seconds\n",
      "Epoch 23. Loss 0.3897. accuracy 0.7181. Elapsed 186 seconds\n",
      "Epoch 23. Loss 0.3918. accuracy 0.7287. Elapsed 187 seconds\n",
      "Epoch 23. Loss 0.3928. accuracy 0.7234. Elapsed 187 seconds\n",
      "Epoch 23. Loss 0.3933. accuracy 0.7181. Elapsed 187 seconds\n",
      "Epoch 23. Loss 0.3989. accuracy 0.7181. Elapsed 188 seconds\n",
      "Epoch 23. Loss 0.3968. accuracy 0.7181. Elapsed 188 seconds\n",
      "Epoch 23. Loss 0.4027. accuracy 0.7128. Elapsed 188 seconds\n",
      "Epoch 23. Loss 0.4020. accuracy 0.7128. Elapsed 189 seconds\n",
      "Epoch 23. Loss 0.4021. accuracy 0.7128. Elapsed 189 seconds\n",
      "Epoch 23. Loss 0.3999. accuracy 0.7234. Elapsed 189 seconds\n",
      "Epoch 23. Loss 0.4040. accuracy 0.7234. Elapsed 190 seconds\n",
      "Epoch 23. Loss 0.4038. accuracy 0.7287. Elapsed 190 seconds\n",
      "Epoch 23. Loss 0.4041. accuracy 0.7074. Elapsed 190 seconds\n",
      "Epoch 23. Loss 0.4076. accuracy 0.7181. Elapsed 191 seconds\n",
      "Epoch 23. Loss 0.4084. accuracy 0.7128. Elapsed 191 seconds\n",
      "Epoch 23. Loss 0.4106. accuracy 0.7128. Elapsed 191 seconds\n",
      "Epoch 23. Loss 0.4119. accuracy 0.7181. Elapsed 192 seconds\n",
      "Epoch 23. Loss 0.4119. accuracy 0.7234. Elapsed 192 seconds\n",
      "Epoch 23. Loss 0.4125. accuracy 0.7181. Elapsed 192 seconds\n",
      "Epoch 23. Loss 0.4106. accuracy 0.7234. Elapsed 192 seconds\n",
      "ep acc 0.7384537636619043\n",
      "Epoch 24. Loss 0.4232. accuracy 0.7181. Elapsed 193 seconds\n",
      "Epoch 24. Loss 0.4167. accuracy 0.7128. Elapsed 193 seconds\n",
      "Epoch 24. Loss 0.4078. accuracy 0.7181. Elapsed 193 seconds\n",
      "Epoch 24. Loss 0.3958. accuracy 0.7181. Elapsed 194 seconds\n",
      "Epoch 24. Loss 0.3953. accuracy 0.7181. Elapsed 194 seconds\n",
      "Epoch 24. Loss 0.3971. accuracy 0.7128. Elapsed 194 seconds\n",
      "Epoch 24. Loss 0.4043. accuracy 0.7074. Elapsed 195 seconds\n",
      "Epoch 24. Loss 0.4093. accuracy 0.7128. Elapsed 195 seconds\n",
      "Epoch 24. Loss 0.4059. accuracy 0.7074. Elapsed 195 seconds\n",
      "Epoch 24. Loss 0.4096. accuracy 0.7234. Elapsed 195 seconds\n",
      "Epoch 24. Loss 0.4128. accuracy 0.7181. Elapsed 196 seconds\n",
      "Epoch 24. Loss 0.4109. accuracy 0.7234. Elapsed 196 seconds\n",
      "Epoch 24. Loss 0.4098. accuracy 0.7074. Elapsed 196 seconds\n",
      "Epoch 24. Loss 0.4136. accuracy 0.7287. Elapsed 196 seconds\n",
      "Epoch 24. Loss 0.4123. accuracy 0.7181. Elapsed 197 seconds\n",
      "Epoch 24. Loss 0.4104. accuracy 0.7181. Elapsed 197 seconds\n",
      "Epoch 24. Loss 0.4142. accuracy 0.7234. Elapsed 197 seconds\n",
      "Epoch 24. Loss 0.4115. accuracy 0.7287. Elapsed 198 seconds\n",
      "Epoch 24. Loss 0.4105. accuracy 0.7287. Elapsed 198 seconds\n",
      "Epoch 24. Loss 0.4108. accuracy 0.7128. Elapsed 198 seconds\n",
      "Epoch 24. Loss 0.4110. accuracy 0.7128. Elapsed 198 seconds\n",
      "Epoch 24. Loss 0.4093. accuracy 0.7128. Elapsed 199 seconds\n",
      "Epoch 24. Loss 0.4111. accuracy 0.7074. Elapsed 199 seconds\n",
      "Epoch 24. Loss 0.4115. accuracy 0.7074. Elapsed 199 seconds\n",
      "Epoch 24. Loss 0.4092. accuracy 0.7128. Elapsed 199 seconds\n",
      "Epoch 24. Loss 0.4095. accuracy 0.7181. Elapsed 200 seconds\n",
      "Epoch 24. Loss 0.4084. accuracy 0.7181. Elapsed 200 seconds\n",
      "ep acc 0.737539401103231\n",
      "Epoch 25. Loss 0.3788. accuracy 0.7074. Elapsed 200 seconds\n",
      "Epoch 25. Loss 0.3799. accuracy 0.7128. Elapsed 200 seconds\n",
      "Epoch 25. Loss 0.3930. accuracy 0.7181. Elapsed 201 seconds\n",
      "Epoch 25. Loss 0.3904. accuracy 0.7234. Elapsed 201 seconds\n",
      "Epoch 25. Loss 0.4068. accuracy 0.7181. Elapsed 201 seconds\n",
      "Epoch 25. Loss 0.4067. accuracy 0.7128. Elapsed 202 seconds\n",
      "Epoch 25. Loss 0.3990. accuracy 0.7128. Elapsed 202 seconds\n",
      "Epoch 25. Loss 0.4028. accuracy 0.7287. Elapsed 202 seconds\n",
      "Epoch 25. Loss 0.4012. accuracy 0.7128. Elapsed 203 seconds\n",
      "Epoch 25. Loss 0.3986. accuracy 0.7181. Elapsed 203 seconds\n",
      "Epoch 25. Loss 0.4010. accuracy 0.7234. Elapsed 203 seconds\n",
      "Epoch 25. Loss 0.4052. accuracy 0.7128. Elapsed 203 seconds\n",
      "Epoch 25. Loss 0.4060. accuracy 0.7234. Elapsed 204 seconds\n",
      "Epoch 25. Loss 0.4062. accuracy 0.7287. Elapsed 204 seconds\n",
      "Epoch 25. Loss 0.4038. accuracy 0.7234. Elapsed 204 seconds\n",
      "Epoch 25. Loss 0.4007. accuracy 0.7234. Elapsed 204 seconds\n",
      "Epoch 25. Loss 0.4020. accuracy 0.7234. Elapsed 205 seconds\n",
      "Epoch 25. Loss 0.4012. accuracy 0.7021. Elapsed 205 seconds\n",
      "Epoch 25. Loss 0.4024. accuracy 0.7181. Elapsed 205 seconds\n",
      "Epoch 25. Loss 0.4006. accuracy 0.7181. Elapsed 206 seconds\n",
      "Epoch 25. Loss 0.4006. accuracy 0.7181. Elapsed 206 seconds\n",
      "Epoch 25. Loss 0.4018. accuracy 0.7181. Elapsed 206 seconds\n",
      "Epoch 25. Loss 0.4011. accuracy 0.7234. Elapsed 206 seconds\n",
      "Epoch 25. Loss 0.4037. accuracy 0.7128. Elapsed 207 seconds\n",
      "Epoch 25. Loss 0.4029. accuracy 0.7234. Elapsed 207 seconds\n",
      "Epoch 25. Loss 0.4031. accuracy 0.7074. Elapsed 207 seconds\n",
      "Epoch 25. Loss 0.4021. accuracy 0.7128. Elapsed 207 seconds\n",
      "ep acc 0.7367454688731285\n",
      "Epoch 26. Loss 0.3685. accuracy 0.7128. Elapsed 208 seconds\n",
      "Epoch 26. Loss 0.3701. accuracy 0.7021. Elapsed 208 seconds\n",
      "Epoch 26. Loss 0.3704. accuracy 0.7181. Elapsed 208 seconds\n",
      "Epoch 26. Loss 0.3762. accuracy 0.7181. Elapsed 209 seconds\n",
      "Epoch 26. Loss 0.3847. accuracy 0.7128. Elapsed 209 seconds\n",
      "Epoch 26. Loss 0.3812. accuracy 0.7181. Elapsed 209 seconds\n",
      "Epoch 26. Loss 0.3909. accuracy 0.7128. Elapsed 210 seconds\n",
      "Epoch 26. Loss 0.3896. accuracy 0.7181. Elapsed 210 seconds\n",
      "Epoch 26. Loss 0.3854. accuracy 0.7181. Elapsed 210 seconds\n",
      "Epoch 26. Loss 0.3892. accuracy 0.7181. Elapsed 210 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26. Loss 0.3942. accuracy 0.7128. Elapsed 211 seconds\n",
      "Epoch 26. Loss 0.3925. accuracy 0.7128. Elapsed 211 seconds\n",
      "Epoch 26. Loss 0.3931. accuracy 0.7181. Elapsed 211 seconds\n",
      "Epoch 26. Loss 0.3935. accuracy 0.7074. Elapsed 212 seconds\n",
      "Epoch 26. Loss 0.3967. accuracy 0.7181. Elapsed 212 seconds\n",
      "Epoch 26. Loss 0.3975. accuracy 0.7128. Elapsed 213 seconds\n",
      "Epoch 26. Loss 0.3976. accuracy 0.7181. Elapsed 213 seconds\n",
      "Epoch 26. Loss 0.3974. accuracy 0.7128. Elapsed 213 seconds\n",
      "Epoch 26. Loss 0.3952. accuracy 0.7074. Elapsed 214 seconds\n",
      "Epoch 26. Loss 0.3965. accuracy 0.7128. Elapsed 214 seconds\n",
      "Epoch 26. Loss 0.3973. accuracy 0.7128. Elapsed 215 seconds\n",
      "Epoch 26. Loss 0.3993. accuracy 0.7128. Elapsed 215 seconds\n",
      "Epoch 26. Loss 0.3992. accuracy 0.7181. Elapsed 215 seconds\n",
      "Epoch 26. Loss 0.4033. accuracy 0.7181. Elapsed 216 seconds\n",
      "Epoch 26. Loss 0.4033. accuracy 0.7181. Elapsed 216 seconds\n",
      "Epoch 26. Loss 0.4028. accuracy 0.7181. Elapsed 216 seconds\n",
      "Epoch 26. Loss 0.4007. accuracy 0.7074. Elapsed 217 seconds\n",
      "ep acc 0.7358837970540099\n",
      "Epoch 27. Loss 0.4626. accuracy 0.7128. Elapsed 217 seconds\n",
      "Epoch 27. Loss 0.4333. accuracy 0.7181. Elapsed 217 seconds\n",
      "Epoch 27. Loss 0.4264. accuracy 0.7128. Elapsed 218 seconds\n",
      "Epoch 27. Loss 0.4044. accuracy 0.7128. Elapsed 218 seconds\n",
      "Epoch 27. Loss 0.4016. accuracy 0.7128. Elapsed 218 seconds\n",
      "Epoch 27. Loss 0.3979. accuracy 0.7074. Elapsed 219 seconds\n",
      "Epoch 27. Loss 0.3913. accuracy 0.7074. Elapsed 219 seconds\n",
      "Epoch 27. Loss 0.3879. accuracy 0.7074. Elapsed 219 seconds\n",
      "Epoch 27. Loss 0.3855. accuracy 0.7074. Elapsed 220 seconds\n",
      "Epoch 27. Loss 0.3897. accuracy 0.7021. Elapsed 220 seconds\n",
      "Epoch 27. Loss 0.3947. accuracy 0.7074. Elapsed 221 seconds\n",
      "Epoch 27. Loss 0.3956. accuracy 0.7128. Elapsed 221 seconds\n",
      "Epoch 27. Loss 0.4015. accuracy 0.7074. Elapsed 221 seconds\n",
      "Epoch 27. Loss 0.4006. accuracy 0.7128. Elapsed 221 seconds\n",
      "Epoch 27. Loss 0.3973. accuracy 0.7074. Elapsed 222 seconds\n",
      "Epoch 27. Loss 0.3986. accuracy 0.7074. Elapsed 222 seconds\n",
      "Epoch 27. Loss 0.3957. accuracy 0.7074. Elapsed 222 seconds\n",
      "Epoch 27. Loss 0.3937. accuracy 0.7128. Elapsed 223 seconds\n",
      "Epoch 27. Loss 0.3938. accuracy 0.7128. Elapsed 223 seconds\n",
      "Epoch 27. Loss 0.3937. accuracy 0.7128. Elapsed 223 seconds\n",
      "Epoch 27. Loss 0.3951. accuracy 0.7128. Elapsed 223 seconds\n",
      "Epoch 27. Loss 0.3971. accuracy 0.7128. Elapsed 224 seconds\n",
      "Epoch 27. Loss 0.3960. accuracy 0.7128. Elapsed 224 seconds\n",
      "Epoch 27. Loss 0.3946. accuracy 0.7181. Elapsed 224 seconds\n",
      "Epoch 27. Loss 0.3941. accuracy 0.7021. Elapsed 225 seconds\n",
      "Epoch 27. Loss 0.3939. accuracy 0.7181. Elapsed 225 seconds\n",
      "Epoch 27. Loss 0.3929. accuracy 0.7128. Elapsed 225 seconds\n",
      "ep acc 0.7349546157662785\n",
      "Epoch 28. Loss 0.3852. accuracy 0.7128. Elapsed 225 seconds\n",
      "Epoch 28. Loss 0.3881. accuracy 0.7128. Elapsed 226 seconds\n",
      "Epoch 28. Loss 0.3691. accuracy 0.7128. Elapsed 226 seconds\n",
      "Epoch 28. Loss 0.3677. accuracy 0.7181. Elapsed 226 seconds\n",
      "Epoch 28. Loss 0.3710. accuracy 0.7128. Elapsed 226 seconds\n",
      "Epoch 28. Loss 0.3737. accuracy 0.7128. Elapsed 227 seconds\n",
      "Epoch 28. Loss 0.3654. accuracy 0.7234. Elapsed 227 seconds\n",
      "Epoch 28. Loss 0.3690. accuracy 0.7234. Elapsed 227 seconds\n",
      "Epoch 28. Loss 0.3707. accuracy 0.7181. Elapsed 227 seconds\n",
      "Epoch 28. Loss 0.3676. accuracy 0.7234. Elapsed 228 seconds\n",
      "Epoch 28. Loss 0.3706. accuracy 0.7181. Elapsed 228 seconds\n",
      "Epoch 28. Loss 0.3690. accuracy 0.7181. Elapsed 228 seconds\n",
      "Epoch 28. Loss 0.3686. accuracy 0.7181. Elapsed 229 seconds\n",
      "Epoch 28. Loss 0.3737. accuracy 0.7234. Elapsed 229 seconds\n",
      "Epoch 28. Loss 0.3718. accuracy 0.7234. Elapsed 229 seconds\n",
      "Epoch 28. Loss 0.3753. accuracy 0.7234. Elapsed 230 seconds\n",
      "Epoch 28. Loss 0.3780. accuracy 0.7234. Elapsed 230 seconds\n",
      "Epoch 28. Loss 0.3751. accuracy 0.7287. Elapsed 230 seconds\n",
      "Epoch 28. Loss 0.3797. accuracy 0.7128. Elapsed 230 seconds\n",
      "Epoch 28. Loss 0.3786. accuracy 0.7181. Elapsed 231 seconds\n",
      "Epoch 28. Loss 0.3802. accuracy 0.7128. Elapsed 231 seconds\n",
      "Epoch 28. Loss 0.3832. accuracy 0.7181. Elapsed 231 seconds\n",
      "Epoch 28. Loss 0.3880. accuracy 0.7021. Elapsed 232 seconds\n",
      "Epoch 28. Loss 0.3899. accuracy 0.7128. Elapsed 232 seconds\n",
      "Epoch 28. Loss 0.3905. accuracy 0.7074. Elapsed 232 seconds\n",
      "Epoch 28. Loss 0.3887. accuracy 0.7128. Elapsed 233 seconds\n",
      "Epoch 28. Loss 0.3881. accuracy 0.7128. Elapsed 233 seconds\n",
      "ep acc 0.7343099178205561\n",
      "Epoch 29. Loss 0.3969. accuracy 0.7074. Elapsed 233 seconds\n",
      "Epoch 29. Loss 0.3755. accuracy 0.7074. Elapsed 234 seconds\n",
      "Epoch 29. Loss 0.3759. accuracy 0.7181. Elapsed 234 seconds\n",
      "Epoch 29. Loss 0.3810. accuracy 0.7181. Elapsed 234 seconds\n",
      "Epoch 29. Loss 0.3702. accuracy 0.7234. Elapsed 235 seconds\n",
      "Epoch 29. Loss 0.3733. accuracy 0.7128. Elapsed 235 seconds\n",
      "Epoch 29. Loss 0.3784. accuracy 0.7074. Elapsed 235 seconds\n",
      "Epoch 29. Loss 0.3774. accuracy 0.7128. Elapsed 235 seconds\n",
      "Epoch 29. Loss 0.3762. accuracy 0.7074. Elapsed 236 seconds\n",
      "Epoch 29. Loss 0.3843. accuracy 0.7074. Elapsed 236 seconds\n",
      "Epoch 29. Loss 0.3831. accuracy 0.7074. Elapsed 236 seconds\n",
      "Epoch 29. Loss 0.3817. accuracy 0.7181. Elapsed 237 seconds\n",
      "Epoch 29. Loss 0.3767. accuracy 0.7181. Elapsed 237 seconds\n",
      "Epoch 29. Loss 0.3809. accuracy 0.7074. Elapsed 237 seconds\n",
      "Epoch 29. Loss 0.3818. accuracy 0.7074. Elapsed 237 seconds\n",
      "Epoch 29. Loss 0.3849. accuracy 0.7128. Elapsed 238 seconds\n",
      "Epoch 29. Loss 0.3895. accuracy 0.7074. Elapsed 238 seconds\n",
      "Epoch 29. Loss 0.3893. accuracy 0.7128. Elapsed 238 seconds\n",
      "Epoch 29. Loss 0.3892. accuracy 0.7128. Elapsed 239 seconds\n",
      "Epoch 29. Loss 0.3908. accuracy 0.7128. Elapsed 239 seconds\n",
      "Epoch 29. Loss 0.3894. accuracy 0.7074. Elapsed 239 seconds\n",
      "Epoch 29. Loss 0.3880. accuracy 0.7128. Elapsed 239 seconds\n",
      "Epoch 29. Loss 0.3894. accuracy 0.7074. Elapsed 240 seconds\n",
      "Epoch 29. Loss 0.3902. accuracy 0.7128. Elapsed 240 seconds\n",
      "Epoch 29. Loss 0.3888. accuracy 0.7128. Elapsed 240 seconds\n",
      "Epoch 29. Loss 0.3891. accuracy 0.7074. Elapsed 241 seconds\n",
      "Epoch 29. Loss 0.3924. accuracy 0.7181. Elapsed 241 seconds\n",
      "ep acc 0.7335330561669521\n",
      "Epoch 30. Loss 0.3912. accuracy 0.7234. Elapsed 241 seconds\n",
      "Epoch 30. Loss 0.3869. accuracy 0.7234. Elapsed 242 seconds\n",
      "Epoch 30. Loss 0.3733. accuracy 0.7181. Elapsed 242 seconds\n",
      "Epoch 30. Loss 0.3712. accuracy 0.7074. Elapsed 242 seconds\n",
      "Epoch 30. Loss 0.3723. accuracy 0.7128. Elapsed 242 seconds\n",
      "Epoch 30. Loss 0.3741. accuracy 0.7234. Elapsed 243 seconds\n",
      "Epoch 30. Loss 0.3731. accuracy 0.7128. Elapsed 243 seconds\n",
      "Epoch 30. Loss 0.3775. accuracy 0.6968. Elapsed 243 seconds\n",
      "Epoch 30. Loss 0.3738. accuracy 0.6968. Elapsed 244 seconds\n",
      "Epoch 30. Loss 0.3759. accuracy 0.7181. Elapsed 244 seconds\n",
      "Epoch 30. Loss 0.3688. accuracy 0.7074. Elapsed 244 seconds\n",
      "Epoch 30. Loss 0.3665. accuracy 0.7021. Elapsed 244 seconds\n",
      "Epoch 30. Loss 0.3676. accuracy 0.6968. Elapsed 245 seconds\n",
      "Epoch 30. Loss 0.3658. accuracy 0.7021. Elapsed 245 seconds\n",
      "Epoch 30. Loss 0.3682. accuracy 0.7074. Elapsed 245 seconds\n",
      "Epoch 30. Loss 0.3711. accuracy 0.7074. Elapsed 246 seconds\n",
      "Epoch 30. Loss 0.3717. accuracy 0.7021. Elapsed 246 seconds\n",
      "Epoch 30. Loss 0.3721. accuracy 0.7021. Elapsed 246 seconds\n",
      "Epoch 30. Loss 0.3723. accuracy 0.7074. Elapsed 247 seconds\n",
      "Epoch 30. Loss 0.3728. accuracy 0.7128. Elapsed 247 seconds\n",
      "Epoch 30. Loss 0.3770. accuracy 0.7074. Elapsed 247 seconds\n",
      "Epoch 30. Loss 0.3773. accuracy 0.7128. Elapsed 247 seconds\n",
      "Epoch 30. Loss 0.3761. accuracy 0.7021. Elapsed 248 seconds\n",
      "Epoch 30. Loss 0.3767. accuracy 0.7181. Elapsed 248 seconds\n",
      "Epoch 30. Loss 0.3771. accuracy 0.7128. Elapsed 249 seconds\n",
      "Epoch 30. Loss 0.3781. accuracy 0.7074. Elapsed 249 seconds\n",
      "Epoch 30. Loss 0.3830. accuracy 0.7074. Elapsed 250 seconds\n",
      "ep acc 0.7327226162332546\n",
      "Total time elapsed: 4 minutes\n"
     ]
    }
   ],
   "source": [
    "tick = time.time()\n",
    "name='NC_4_26_sgd_ep'\n",
    "epoch_losses = []\n",
    "epoch_accs = []\n",
    "best_score= 0.5\n",
    "for epoch_num in range(1, num_epochs + 1):\n",
    "    batch_losses = []\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        ### YOUR CODE BELOW ###\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Extract the inputs and the targets\n",
    "        inputs, targets = batch\n",
    "        # Transfer the inputs and the targets to GPUs, if available\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = torch.FloatTensor(inputs.float()).cuda()\n",
    "            targets = torch.LongTensor(targets).cuda()\n",
    "        # Run the model\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs,targets)\n",
    "        \n",
    "        \n",
    "        # Backpropagate the error\n",
    "        loss.backward(retain_graph=True)\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Append the loss\n",
    "        batch_losses.append(float (loss))\n",
    "        ### YOUR CODE ABOVE ###\n",
    "        epoch_loss = np.mean(np.array(batch_losses))\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        \n",
    "        acc = compute_accuracy(val_data_set)\n",
    "        epoch_accs.append(acc)\n",
    "        \n",
    "\n",
    "        if epoch_num % report_every == 0:\n",
    "            tock = time.time()\n",
    "            print(\"Epoch {}. Loss {:.4f}. accuracy {:.4f}. Elapsed {:.0f} seconds\".format(epoch_num, epoch_loss,acc, tock-tick))\n",
    "    \n",
    "    epoch_acc = np.mean(np.array(epoch_accs))\n",
    "    print('ep acc',epoch_acc)\n",
    "    if epoch_acc > best_score:\n",
    "            best_score = epoch_acc\n",
    "            print('new best saving model')\n",
    "            save('{}{}_best_acc_{:.2f}'.format(name,epoch_num,epoch_acc))\n",
    "     \n",
    "    #print('saving model')\n",
    "    #save(name+ str(epoch_num))\n",
    "\n",
    "print(\"Total time elapsed: {:.0f} minutes\".format((tock-tick)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train_data_set = None\n",
    "test_data_set = NoContextDataset(file='story_cloze_data/cloze_test_test__spring2016 - cloze_test_ALL_test.csv',vocab=voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data_set= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(name):\n",
    "    l_model = NoContextModel()\n",
    "    l_model.load_state_dict(torch.load('saved_models/{}.save'.format(name)))\n",
    "    return l_model\n",
    "model = load('NC_4_26_sgd_ep30_best_acc_0.70')\n",
    "#print('model',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6932121859967931"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(test_data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
