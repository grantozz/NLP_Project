{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "sys.path.append('skip-thoughts.torch/pytorch')\n",
    "from skipthoughts import UniSkip,BiSkip\n",
    "import pandas as pd\n",
    "from Vocabulary import Vocabulary, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vocab(tokens):\n",
    "    voc = Vocabulary(['<PAD>','<UNK>'])\n",
    "    voc.add_tokens(tokens)\n",
    "    print('vocab len is {}'.format(len(voc.w2idx)))\n",
    "    return voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file='story_cloze_data/cloze_test_val__spring2016 - cloze_test_ALL_val.csv'):\n",
    "    df= pd.read_csv(file)\n",
    "    df = df.drop('InputStoryid',axis=1)\n",
    "    targets = df['AnswerRightEnding']\n",
    "    df = df.drop('AnswerRightEnding',axis=1)\n",
    "    df = df.drop('InputSentence1',axis=1)\n",
    "    df = df.drop('InputSentence2',axis=1)\n",
    "    df = df.drop('InputSentence3',axis=1)\n",
    "    \n",
    "    voc_str= ''\n",
    "    for index, row in df.iterrows():\n",
    "        voc_str+=' '.join(list(row)) + ' '\n",
    "        \n",
    "    df['AnswerRightEnding'] = targets\n",
    "    return df,make_vocab(preprocess(voc_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import OrderedDict \n",
    "class LastSentenceDataset(Dataset):\n",
    "    def __init__(self,file='story_cloze_data/cloze_test_val__spring2016 - cloze_test_ALL_val.csv',vocab=None,df=None):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        created_df, created_vocab = load_data(file)\n",
    "        if df is None:\n",
    "            df = created_df\n",
    "        if vocab:\n",
    "            self.vocab = vocab\n",
    "        else:\n",
    "            self.vocab = created_vocab\n",
    "      \n",
    "        \n",
    "        self.dir_st = 'data/skip-thoughts'\n",
    "        self.biskip = BiSkip(self.dir_st, self.vocab.convert_to_list())\n",
    "        \n",
    "        self.uniskip = UniSkip(self.dir_st, self.vocab.convert_to_list())\n",
    "        \n",
    "        \n",
    "        self.data = self.make_data(df)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            idx\n",
    "        Returns: skip thought embedding of ending and 0/1 if it is the right ending \n",
    "\n",
    "        \"\"\"\n",
    "        return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns len of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "       \n",
    "    def make_data(self, df):\n",
    "        data = []\n",
    "        total = df.index\n",
    "        print('skip thought encoding dataset')\n",
    "        for i in total:\n",
    "            #print(row['RandomFifthSentenceQuiz1'],row['RandomFifthSentenceQuiz2'])\n",
    "            progress(i,len(total))\n",
    "            endings =  self.gen_embbeding(df.at[i,'RandomFifthSentenceQuiz1'], \n",
    "                                          df.at[i,'RandomFifthSentenceQuiz2'],\n",
    "                                          df.at[i,'InputSentence4'])\n",
    "            if df.at[i,'AnswerRightEnding'] == 1:\n",
    "                data.append((endings[0],1))\n",
    "                data.append((endings[1],0))\n",
    "            else:\n",
    "                data.append((endings[0],0))\n",
    "                data.append((endings[1],1))\n",
    "        return data\n",
    "    \n",
    "\n",
    "    def zero_pad(self,l,n):\n",
    "        l = (l + n * [0])[:n]\n",
    "        return l\n",
    "    \n",
    "    def pad_input(self,d):\n",
    "        d = OrderedDict(sorted(d.items(), key=lambda s: len(s[1])))\n",
    "        for k,v in d.items():\n",
    "            d[k]= self.zero_pad(v,len(list(d.items())[-1][1]))\n",
    "        return d\n",
    "        \n",
    "    def gen_embbeding(self,sent1,sent2,last_sent):\n",
    "        d = dict()\n",
    "        sent1 = preprocess(sent1)\n",
    "        sent2 = preprocess(sent2)\n",
    "        ls = preprocess(last_sent)\n",
    "        #remove random n token that is in one sentence\n",
    "        if 'n' in sent2:\n",
    "            sent2.remove('n')\n",
    "        d['sent1'] = self.vocab.get_sentence(sent1)\n",
    "        d['sent2'] = self.vocab.get_sentence(sent2)\n",
    "        d['ls'] = self.vocab.get_sentence(ls)\n",
    "        d = self.pad_input(d)\n",
    "        \n",
    "        batch = torch.LongTensor([d['sent1'],d['sent2'], d['ls']]) \n",
    "        top_half = self.uniskip(batch)\n",
    "        bottom_half = self.biskip(batch)\n",
    "        combine_skip = torch.cat([top_half,bottom_half],dim=1)\n",
    "        end1 = combine_skip[0]\n",
    "        end2 = combine_skip[1]\n",
    "        ls = combine_skip[2]\n",
    "        \n",
    "        #print(end1[:20],end2[:20])\n",
    "        end1.add_(ls)\n",
    "        end2.add_(ls)\n",
    "        #print('ls',ls[:20])\n",
    "        #print('after',end1[:20])\n",
    "        return end1,end2    \n",
    "    \n",
    "def progress(count, total, status=''):\n",
    "    bar_len = 60\n",
    "    filled_len = int(round(bar_len * count / float(total)))\n",
    "\n",
    "    percents = round(100.0 * count / float(total), 1)\n",
    "    bar = '=' * filled_len + '-' * (bar_len - filled_len)\n",
    "\n",
    "    sys.stdout.write('[%s] %s%s ...%s\\r' % (bar, percents, '%', status))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hd1 = torch.nn.Linear(4800, 2400)\n",
    "        self.hd2 = torch.nn.Linear(2400, 1200)\n",
    "        self.hd3 = torch.nn.Linear(1200, 600)\n",
    "        self.output = torch.nn.Linear(600, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.hd1(x))\n",
    "        x = torch.nn.functional.relu(self.hd2(x))\n",
    "        x = torch.nn.functional.relu(self.hd3(x))\n",
    "        x = self.output(x)\n",
    "        #print('output',x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(pair,model):\n",
    "    '''true if model predicts right'''\n",
    "    ending1, ending2 = pair\n",
    "    if ending1[1] == 1:\n",
    "        target = 1\n",
    "    else:\n",
    "        target =  2 \n",
    "        \n",
    "    ending1 = ending1[0]\n",
    "    ending2 = ending2[0]\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        ending1 = ending1.cuda()\n",
    "        ending2 = ending2.cuda()\n",
    "    res1 = model(ending1)\n",
    "    res2 = model(ending2)\n",
    "    softm = torch.nn.Softmax(dim=0)\n",
    "    prob_end1_right = softm(res1)[1].item() \n",
    "    prob_end2_right = softm(res2)[1].item()\n",
    "    \n",
    "    if prob_end1_right > prob_end2_right:\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 2\n",
    "    \n",
    "    if pred == target:\n",
    "        return True\n",
    "    else: \n",
    "        #print(prob_end1_right,prob_end2_right,pred,target)\n",
    "        return False\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(data_set):\n",
    "    num_right = 0\n",
    "    for i in range(0,len(data_set),2):\n",
    "        if score((data_set[i],data_set[i+1]),model):\n",
    "            num_right+=1\n",
    "    return num_right / (len(data_set)/2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(name):\n",
    "    torch.save(model.state_dict(), 'saved_models/{}.save'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab len is 5303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df, voc = load_data()\n",
    "train, val = train_test_split(df, test_size=0.1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-paper')\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "num_epochs = 10\n",
    "report_every = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab len is 5303\n",
      "Warning: 47/930911 words are not in dictionary, thus set UNK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/cs/undergrad/2019/gnosborn/nlp/env/lib/python3.6/site-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 47/930911 words are not in dictionary, thus set UNK\n",
      "skip thought encoding dataset\n",
      "[============================================================] 99.9% ...\r"
     ]
    }
   ],
   "source": [
    "train_data_set = LastSentenceDataset(df=train,vocab=voc)\n",
    "data_loader = torch.utils.data.DataLoader(train_data_set, batch_size=batch_size, shuffle=True,num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab len is 5303\n",
      "Warning: 47/930911 words are not in dictionary, thus set UNK\n",
      "Warning: 47/930911 words are not in dictionary, thus set UNK\n",
      "skip thought encoding dataset\n",
      "[=====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] 994.7% ...\r"
     ]
    }
   ],
   "source": [
    "val_data_set = LastSentenceDataset(file='story_cloze_data/cloze_test_val__spring2016 - cloze_test_ALL_val.csv',df=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSModel()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Loss 0.6921. accuracy 0.4521. Elapsed 57 seconds\n",
      "Epoch 1. Loss 46.2648. accuracy 0.4521. Elapsed 111 seconds\n",
      "Epoch 1. Loss 84.0700. accuracy 0.4894. Elapsed 167 seconds\n",
      "new best saving model\n",
      "Epoch 1. Loss 66.0568. accuracy 0.5479. Elapsed 226 seconds\n",
      "Epoch 1. Loss 52.9952. accuracy 0.4521. Elapsed 283 seconds\n",
      "new best saving model\n",
      "Epoch 1. Loss 44.3533. accuracy 0.5532. Elapsed 344 seconds\n",
      "Epoch 1. Loss 38.2443. accuracy 0.4947. Elapsed 401 seconds\n",
      "Epoch 1. Loss 33.5493. accuracy 0.4734. Elapsed 459 seconds\n",
      "Epoch 1. Loss 29.9440. accuracy 0.4681. Elapsed 517 seconds\n",
      "Epoch 1. Loss 27.0190. accuracy 0.5053. Elapsed 573 seconds\n",
      "Epoch 1. Loss 24.7128. accuracy 0.4734. Elapsed 630 seconds\n",
      "Epoch 1. Loss 22.7253. accuracy 0.5426. Elapsed 687 seconds\n",
      "Epoch 1. Loss 21.0309. accuracy 0.4734. Elapsed 744 seconds\n",
      "Epoch 1. Loss 19.5800. accuracy 0.5479. Elapsed 802 seconds\n",
      "new best saving model\n",
      "Epoch 1. Loss 18.3227. accuracy 0.5851. Elapsed 863 seconds\n",
      "Epoch 1. Loss 17.2206. accuracy 0.5851. Elapsed 920 seconds\n",
      "Epoch 1. Loss 16.2483. accuracy 0.5638. Elapsed 978 seconds\n",
      "Epoch 1. Loss 15.3839. accuracy 0.5319. Elapsed 1036 seconds\n",
      "Epoch 1. Loss 14.6146. accuracy 0.4202. Elapsed 1093 seconds\n",
      "Epoch 1. Loss 13.9185. accuracy 0.5532. Elapsed 1148 seconds\n",
      "Epoch 1. Loss 13.2891. accuracy 0.4840. Elapsed 1207 seconds\n",
      "Epoch 1. Loss 12.7177. accuracy 0.5479. Elapsed 1264 seconds\n",
      "Epoch 1. Loss 12.1946. accuracy 0.5532. Elapsed 1320 seconds\n",
      "Epoch 1. Loss 11.7158. accuracy 0.5798. Elapsed 1378 seconds\n",
      "Epoch 1. Loss 11.2749. accuracy 0.5372. Elapsed 1440 seconds\n",
      "Epoch 1. Loss 10.8679. accuracy 0.5585. Elapsed 1501 seconds\n",
      "Epoch 1. Loss 10.4913. accuracy 0.5691. Elapsed 1519 seconds\n",
      "saving model\n",
      "Epoch 2. Loss 0.6859. accuracy 0.5798. Elapsed 1581 seconds\n",
      "Epoch 2. Loss 0.6905. accuracy 0.5213. Elapsed 1639 seconds\n",
      "Epoch 2. Loss 0.6896. accuracy 0.5585. Elapsed 1701 seconds\n",
      "Epoch 2. Loss 0.6980. accuracy 0.5053. Elapsed 1760 seconds\n",
      "Epoch 2. Loss 0.6966. accuracy 0.5745. Elapsed 1818 seconds\n",
      "Epoch 2. Loss 0.6947. accuracy 0.5638. Elapsed 1876 seconds\n",
      "Epoch 2. Loss 0.6954. accuracy 0.5532. Elapsed 1938 seconds\n",
      "Epoch 2. Loss 0.6952. accuracy 0.5585. Elapsed 1996 seconds\n",
      "Epoch 2. Loss 0.6973. accuracy 0.5691. Elapsed 2056 seconds\n",
      "Epoch 2. Loss 0.6960. accuracy 0.5691. Elapsed 2116 seconds\n",
      "new best saving model\n",
      "Epoch 2. Loss 0.6968. accuracy 0.5957. Elapsed 2178 seconds\n",
      "Epoch 2. Loss 0.6961. accuracy 0.5532. Elapsed 2237 seconds\n",
      "Epoch 2. Loss 0.6950. accuracy 0.5532. Elapsed 2295 seconds\n",
      "Epoch 2. Loss 0.6975. accuracy 0.5851. Elapsed 2356 seconds\n",
      "Epoch 2. Loss 0.6970. accuracy 0.5479. Elapsed 2415 seconds\n",
      "Epoch 2. Loss 0.6968. accuracy 0.5691. Elapsed 2476 seconds\n",
      "Epoch 2. Loss 0.6963. accuracy 0.5745. Elapsed 2537 seconds\n",
      "Epoch 2. Loss 0.6961. accuracy 0.5160. Elapsed 2597 seconds\n",
      "Epoch 2. Loss 0.6959. accuracy 0.5479. Elapsed 2658 seconds\n",
      "Epoch 2. Loss 0.6959. accuracy 0.4681. Elapsed 2719 seconds\n",
      "Epoch 2. Loss 0.6987. accuracy 0.5266. Elapsed 2779 seconds\n",
      "Epoch 2. Loss 0.6989. accuracy 0.5638. Elapsed 2839 seconds\n",
      "Epoch 2. Loss 0.6987. accuracy 0.5053. Elapsed 2899 seconds\n",
      "Epoch 2. Loss 0.6989. accuracy 0.5266. Elapsed 2957 seconds\n",
      "Epoch 2. Loss 0.7000. accuracy 0.5426. Elapsed 3017 seconds\n",
      "Epoch 2. Loss 0.6996. accuracy 0.5426. Elapsed 3075 seconds\n",
      "Epoch 2. Loss 0.6997. accuracy 0.5745. Elapsed 3093 seconds\n",
      "saving model\n",
      "Epoch 3. Loss 0.6865. accuracy 0.5638. Elapsed 3155 seconds\n",
      "Epoch 3. Loss 0.6867. accuracy 0.5585. Elapsed 3215 seconds\n",
      "Epoch 3. Loss 0.6872. accuracy 0.5904. Elapsed 3277 seconds\n",
      "Epoch 3. Loss 0.6878. accuracy 0.5372. Elapsed 3337 seconds\n",
      "Epoch 3. Loss 0.6922. accuracy 0.5532. Elapsed 3397 seconds\n",
      "Epoch 3. Loss 0.6922. accuracy 0.5638. Elapsed 3456 seconds\n",
      "Epoch 3. Loss 0.6925. accuracy 0.5319. Elapsed 3515 seconds\n",
      "Epoch 3. Loss 0.6924. accuracy 0.5479. Elapsed 3574 seconds\n",
      "Epoch 3. Loss 0.6909. accuracy 0.5691. Elapsed 3633 seconds\n",
      "Epoch 3. Loss 0.6909. accuracy 0.5426. Elapsed 3692 seconds\n",
      "Epoch 3. Loss 0.6907. accuracy 0.5904. Elapsed 3751 seconds\n",
      "Epoch 3. Loss 0.6906. accuracy 0.5479. Elapsed 3812 seconds\n",
      "Epoch 3. Loss 0.6909. accuracy 0.5532. Elapsed 3869 seconds\n",
      "Epoch 3. Loss 0.6909. accuracy 0.5851. Elapsed 3928 seconds\n",
      "Epoch 3. Loss 0.6908. accuracy 0.5000. Elapsed 3987 seconds\n",
      "Epoch 3. Loss 0.6913. accuracy 0.5638. Elapsed 4047 seconds\n",
      "Epoch 3. Loss 0.6912. accuracy 0.5638. Elapsed 4106 seconds\n",
      "Epoch 3. Loss 0.6912. accuracy 0.5638. Elapsed 4168 seconds\n",
      "Epoch 3. Loss 0.6905. accuracy 0.5426. Elapsed 4227 seconds\n",
      "Epoch 3. Loss 0.6908. accuracy 0.5638. Elapsed 4287 seconds\n",
      "Epoch 3. Loss 0.6910. accuracy 0.5585. Elapsed 4347 seconds\n",
      "Epoch 3. Loss 0.6917. accuracy 0.5585. Elapsed 4407 seconds\n",
      "Epoch 3. Loss 0.6917. accuracy 0.5426. Elapsed 4465 seconds\n",
      "Epoch 3. Loss 0.6916. accuracy 0.5638. Elapsed 4524 seconds\n",
      "Epoch 3. Loss 0.6914. accuracy 0.5638. Elapsed 4585 seconds\n",
      "Epoch 3. Loss 0.6913. accuracy 0.5532. Elapsed 4645 seconds\n",
      "Epoch 3. Loss 0.6911. accuracy 0.5851. Elapsed 4662 seconds\n",
      "saving model\n",
      "Epoch 4. Loss 0.6851. accuracy 0.5638. Elapsed 4726 seconds\n",
      "Epoch 4. Loss 0.6810. accuracy 0.5691. Elapsed 4787 seconds\n",
      "Epoch 4. Loss 0.6825. accuracy 0.5638. Elapsed 4846 seconds\n",
      "Epoch 4. Loss 0.6786. accuracy 0.5745. Elapsed 4906 seconds\n",
      "Epoch 4. Loss 0.6762. accuracy 0.5638. Elapsed 4966 seconds\n",
      "Epoch 4. Loss 0.6809. accuracy 0.5532. Elapsed 5023 seconds\n",
      "Epoch 4. Loss 0.6845. accuracy 0.5585. Elapsed 5083 seconds\n",
      "Epoch 4. Loss 0.6844. accuracy 0.5585. Elapsed 5142 seconds\n",
      "Epoch 4. Loss 0.6824. accuracy 0.5106. Elapsed 5200 seconds\n",
      "Epoch 4. Loss 0.6837. accuracy 0.5106. Elapsed 5259 seconds\n",
      "Epoch 4. Loss 0.6856. accuracy 0.5691. Elapsed 5318 seconds\n",
      "Epoch 4. Loss 0.6859. accuracy 0.5585. Elapsed 5376 seconds\n",
      "Epoch 4. Loss 0.6846. accuracy 0.5691. Elapsed 5434 seconds\n",
      "Epoch 4. Loss 0.6848. accuracy 0.5691. Elapsed 5493 seconds\n",
      "Epoch 4. Loss 0.6848. accuracy 0.5532. Elapsed 5551 seconds\n",
      "Epoch 4. Loss 0.6838. accuracy 0.5638. Elapsed 5609 seconds\n",
      "Epoch 4. Loss 0.6835. accuracy 0.5532. Elapsed 5667 seconds\n",
      "Epoch 4. Loss 0.6831. accuracy 0.5691. Elapsed 5725 seconds\n",
      "Epoch 4. Loss 0.6826. accuracy 0.5851. Elapsed 5784 seconds\n",
      "Epoch 4. Loss 0.6828. accuracy 0.5426. Elapsed 5843 seconds\n",
      "Epoch 4. Loss 0.6826. accuracy 0.5745. Elapsed 5903 seconds\n",
      "Epoch 4. Loss 0.6825. accuracy 0.5904. Elapsed 5961 seconds\n",
      "Epoch 4. Loss 0.6819. accuracy 0.5798. Elapsed 6019 seconds\n",
      "Epoch 4. Loss 0.6818. accuracy 0.5851. Elapsed 6080 seconds\n",
      "new best saving model\n",
      "Epoch 4. Loss 0.6819. accuracy 0.6117. Elapsed 6141 seconds\n",
      "Epoch 4. Loss 0.6831. accuracy 0.6011. Elapsed 6198 seconds\n",
      "Epoch 4. Loss 0.6833. accuracy 0.5426. Elapsed 6215 seconds\n",
      "saving model\n",
      "Epoch 5. Loss 0.6687. accuracy 0.5372. Elapsed 6276 seconds\n",
      "Epoch 5. Loss 0.6794. accuracy 0.5798. Elapsed 6335 seconds\n",
      "Epoch 5. Loss 0.6727. accuracy 0.5957. Elapsed 6395 seconds\n",
      "Epoch 5. Loss 0.6744. accuracy 0.5851. Elapsed 6453 seconds\n",
      "Epoch 5. Loss 0.6778. accuracy 0.5904. Elapsed 6511 seconds\n",
      "Epoch 5. Loss 0.6755. accuracy 0.5585. Elapsed 6569 seconds\n",
      "Epoch 5. Loss 0.6739. accuracy 0.5851. Elapsed 6627 seconds\n",
      "Epoch 5. Loss 0.6806. accuracy 0.5745. Elapsed 6688 seconds\n",
      "Epoch 5. Loss 0.6812. accuracy 0.5851. Elapsed 6747 seconds\n",
      "Epoch 5. Loss 0.6805. accuracy 0.5904. Elapsed 6807 seconds\n",
      "Epoch 5. Loss 0.6778. accuracy 0.6011. Elapsed 6864 seconds\n",
      "Epoch 5. Loss 0.6760. accuracy 0.6011. Elapsed 6923 seconds\n",
      "Epoch 5. Loss 0.6739. accuracy 0.5851. Elapsed 6983 seconds\n",
      "Epoch 5. Loss 0.6726. accuracy 0.5798. Elapsed 7040 seconds\n",
      "new best saving model\n",
      "Epoch 5. Loss 0.6720. accuracy 0.6330. Elapsed 7102 seconds\n",
      "Epoch 5. Loss 0.6723. accuracy 0.6223. Elapsed 7161 seconds\n",
      "Epoch 5. Loss 0.6739. accuracy 0.6117. Elapsed 7221 seconds\n",
      "Epoch 5. Loss 0.6729. accuracy 0.6223. Elapsed 7281 seconds\n",
      "new best saving model\n",
      "Epoch 5. Loss 0.6720. accuracy 0.6489. Elapsed 7344 seconds\n",
      "Epoch 5. Loss 0.6713. accuracy 0.6011. Elapsed 7401 seconds\n",
      "Epoch 5. Loss 0.6707. accuracy 0.6117. Elapsed 7459 seconds\n",
      "Epoch 5. Loss 0.6707. accuracy 0.5904. Elapsed 7515 seconds\n",
      "Epoch 5. Loss 0.6708. accuracy 0.5798. Elapsed 7573 seconds\n",
      "Epoch 5. Loss 0.6707. accuracy 0.5798. Elapsed 7630 seconds\n",
      "Epoch 5. Loss 0.6728. accuracy 0.5957. Elapsed 7687 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5. Loss 0.6728. accuracy 0.5798. Elapsed 7746 seconds\n",
      "Epoch 5. Loss 0.6739. accuracy 0.6117. Elapsed 7763 seconds\n",
      "saving model\n",
      "Epoch 6. Loss 0.6546. accuracy 0.5851. Elapsed 7825 seconds\n",
      "Epoch 6. Loss 0.6536. accuracy 0.6170. Elapsed 7884 seconds\n",
      "Epoch 6. Loss 0.6537. accuracy 0.6011. Elapsed 7941 seconds\n",
      "Epoch 6. Loss 0.6509. accuracy 0.5957. Elapsed 8000 seconds\n",
      "Epoch 6. Loss 0.6455. accuracy 0.5957. Elapsed 8059 seconds\n",
      "Epoch 6. Loss 0.6388. accuracy 0.6011. Elapsed 8116 seconds\n",
      "Epoch 6. Loss 0.6453. accuracy 0.5957. Elapsed 8173 seconds\n",
      "Epoch 6. Loss 0.6501. accuracy 0.6277. Elapsed 8230 seconds\n",
      "Epoch 6. Loss 0.6556. accuracy 0.5798. Elapsed 8289 seconds\n",
      "Epoch 6. Loss 0.6570. accuracy 0.5957. Elapsed 8346 seconds\n",
      "Epoch 6. Loss 0.6579. accuracy 0.5904. Elapsed 8405 seconds\n",
      "Epoch 6. Loss 0.6576. accuracy 0.5798. Elapsed 8464 seconds\n",
      "Epoch 6. Loss 0.6535. accuracy 0.5904. Elapsed 8520 seconds\n",
      "Epoch 6. Loss 0.6514. accuracy 0.5691. Elapsed 8576 seconds\n",
      "Epoch 6. Loss 0.6535. accuracy 0.5638. Elapsed 8634 seconds\n",
      "Epoch 6. Loss 0.6525. accuracy 0.5904. Elapsed 8692 seconds\n",
      "Epoch 6. Loss 0.6525. accuracy 0.5904. Elapsed 8750 seconds\n",
      "Epoch 6. Loss 0.6516. accuracy 0.5957. Elapsed 8811 seconds\n",
      "Epoch 6. Loss 0.6533. accuracy 0.5691. Elapsed 8870 seconds\n",
      "Epoch 6. Loss 0.6535. accuracy 0.6011. Elapsed 8931 seconds\n",
      "Epoch 6. Loss 0.6529. accuracy 0.6064. Elapsed 8990 seconds\n",
      "Epoch 6. Loss 0.6511. accuracy 0.5479. Elapsed 9047 seconds\n",
      "Epoch 6. Loss 0.6515. accuracy 0.5957. Elapsed 9109 seconds\n",
      "Epoch 6. Loss 0.6519. accuracy 0.5957. Elapsed 9168 seconds\n",
      "Epoch 6. Loss 0.6531. accuracy 0.6117. Elapsed 9228 seconds\n",
      "Epoch 6. Loss 0.6531. accuracy 0.6170. Elapsed 9288 seconds\n",
      "Epoch 6. Loss 0.6543. accuracy 0.5957. Elapsed 9305 seconds\n",
      "saving model\n",
      "Epoch 7. Loss 0.6682. accuracy 0.5745. Elapsed 9369 seconds\n",
      "Epoch 7. Loss 0.6742. accuracy 0.6117. Elapsed 9428 seconds\n",
      "Epoch 7. Loss 0.6623. accuracy 0.6011. Elapsed 9484 seconds\n",
      "Epoch 7. Loss 0.6575. accuracy 0.5957. Elapsed 9539 seconds\n",
      "Epoch 7. Loss 0.6470. accuracy 0.6011. Elapsed 9599 seconds\n",
      "Epoch 7. Loss 0.6473. accuracy 0.6011. Elapsed 9657 seconds\n",
      "Epoch 7. Loss 0.6450. accuracy 0.5745. Elapsed 9717 seconds\n",
      "Epoch 7. Loss 0.6395. accuracy 0.5904. Elapsed 9773 seconds\n",
      "Epoch 7. Loss 0.6340. accuracy 0.5851. Elapsed 9833 seconds\n",
      "Epoch 7. Loss 0.6308. accuracy 0.5798. Elapsed 9892 seconds\n",
      "Epoch 7. Loss 0.6302. accuracy 0.5585. Elapsed 9950 seconds\n",
      "Epoch 7. Loss 0.6326. accuracy 0.6064. Elapsed 10008 seconds\n",
      "Epoch 7. Loss 0.6359. accuracy 0.5745. Elapsed 10064 seconds\n",
      "Epoch 7. Loss 0.6390. accuracy 0.5798. Elapsed 10123 seconds\n",
      "Epoch 7. Loss 0.6369. accuracy 0.5904. Elapsed 10180 seconds\n",
      "Epoch 7. Loss 0.6366. accuracy 0.5745. Elapsed 10239 seconds\n",
      "Epoch 7. Loss 0.6358. accuracy 0.5904. Elapsed 10296 seconds\n",
      "Epoch 7. Loss 0.6377. accuracy 0.5798. Elapsed 10355 seconds\n",
      "Epoch 7. Loss 0.6375. accuracy 0.5904. Elapsed 10413 seconds\n",
      "Epoch 7. Loss 0.6366. accuracy 0.5904. Elapsed 10473 seconds\n",
      "Epoch 7. Loss 0.6361. accuracy 0.5798. Elapsed 10532 seconds\n",
      "Epoch 7. Loss 0.6352. accuracy 0.5904. Elapsed 10588 seconds\n",
      "Epoch 7. Loss 0.6366. accuracy 0.5798. Elapsed 10647 seconds\n",
      "Epoch 7. Loss 0.6425. accuracy 0.5745. Elapsed 10706 seconds\n",
      "Epoch 7. Loss 0.6491. accuracy 0.5957. Elapsed 10762 seconds\n",
      "Epoch 7. Loss 0.6488. accuracy 0.5585. Elapsed 10820 seconds\n",
      "Epoch 7. Loss 0.6475. accuracy 0.5585. Elapsed 10837 seconds\n",
      "saving model\n",
      "Epoch 8. Loss 0.5930. accuracy 0.5638. Elapsed 10899 seconds\n",
      "Epoch 8. Loss 0.5899. accuracy 0.5426. Elapsed 10957 seconds\n",
      "Epoch 8. Loss 0.6092. accuracy 0.5372. Elapsed 11016 seconds\n",
      "Epoch 8. Loss 0.6139. accuracy 0.5479. Elapsed 11075 seconds\n",
      "Epoch 8. Loss 0.6211. accuracy 0.5745. Elapsed 11134 seconds\n",
      "Epoch 8. Loss 0.6185. accuracy 0.5745. Elapsed 11193 seconds\n",
      "Epoch 8. Loss 0.6139. accuracy 0.6011. Elapsed 11252 seconds\n",
      "Epoch 8. Loss 0.6212. accuracy 0.5585. Elapsed 11309 seconds\n",
      "Epoch 8. Loss 0.6202. accuracy 0.5798. Elapsed 11368 seconds\n",
      "Epoch 8. Loss 0.6096. accuracy 0.5904. Elapsed 11427 seconds\n",
      "Epoch 8. Loss 0.6124. accuracy 0.5851. Elapsed 11485 seconds\n",
      "Epoch 8. Loss 0.6150. accuracy 0.5904. Elapsed 11541 seconds\n",
      "Epoch 8. Loss 0.6148. accuracy 0.6064. Elapsed 11599 seconds\n",
      "Epoch 8. Loss 0.6119. accuracy 0.5638. Elapsed 11658 seconds\n",
      "Epoch 8. Loss 0.6078. accuracy 0.5798. Elapsed 11717 seconds\n",
      "Epoch 8. Loss 0.6028. accuracy 0.5798. Elapsed 11775 seconds\n",
      "Epoch 8. Loss 0.6009. accuracy 0.5585. Elapsed 11833 seconds\n",
      "Epoch 8. Loss 0.5994. accuracy 0.5691. Elapsed 11891 seconds\n",
      "Epoch 8. Loss 0.5991. accuracy 0.5479. Elapsed 11948 seconds\n",
      "Epoch 8. Loss 0.5974. accuracy 0.5532. Elapsed 12005 seconds\n",
      "Epoch 8. Loss 0.5981. accuracy 0.5691. Elapsed 12063 seconds\n",
      "Epoch 8. Loss 0.5977. accuracy 0.5372. Elapsed 12122 seconds\n",
      "Epoch 8. Loss 0.6075. accuracy 0.5798. Elapsed 12180 seconds\n",
      "Epoch 8. Loss 0.6152. accuracy 0.5745. Elapsed 12237 seconds\n",
      "Epoch 8. Loss 0.6169. accuracy 0.5851. Elapsed 12296 seconds\n",
      "Epoch 8. Loss 0.6178. accuracy 0.5798. Elapsed 12354 seconds\n",
      "Epoch 8. Loss 0.6172. accuracy 0.5745. Elapsed 12370 seconds\n",
      "saving model\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/nlp/env/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nlp/env/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nlp/env/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mserialized_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_should_read_directly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: write(): fd 79 failed with No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ba802eb233ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch {}. Loss {:.4f}. accuracy {:.4f}. Elapsed {:.0f} seconds\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtock\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saving model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total time elapsed: {:.0f} minutes\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtock\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-8f166a72c2fd>\u001b[0m in \u001b[0;36msave\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'saved_models/{}.save'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/nlp/env/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \"\"\"\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nlp/env/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "tick = time.time()\n",
    "name='LS_adagrad'\n",
    "epoch_losses = []\n",
    "best_score= 0.5\n",
    "for epoch_num in range(1, num_epochs + 1):\n",
    "    batch_losses = []\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        ### YOUR CODE BELOW ###\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Extract the inputs and the targets\n",
    "        inputs, targets = batch\n",
    "        # Transfer the inputs and the targets to GPUs, if available\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = torch.FloatTensor(inputs.float()).cuda()\n",
    "            targets = torch.LongTensor(targets).cuda()\n",
    "        # Run the model\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs,targets)\n",
    "        \n",
    "        \n",
    "        # Backpropagate the error\n",
    "        loss.backward(retain_graph=True)\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Append the loss\n",
    "        batch_losses.append(float (loss))\n",
    "        ### YOUR CODE ABOVE ###\n",
    "        epoch_loss = np.mean(np.array(batch_losses))\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        \n",
    "        acc = compute_accuracy(val_data_set)\n",
    "        if acc > best_score:\n",
    "            best_score = acc\n",
    "            print('new best saving model')\n",
    "            save('{}{}_best_acc_{:.2f}'.format(name,epoch_num,acc))\n",
    "\n",
    "        if epoch_num % report_every == 0:\n",
    "            tock = time.time()\n",
    "            print(\"Epoch {}. Loss {:.4f}. accuracy {:.4f}. Elapsed {:.0f} seconds\".format(epoch_num, epoch_loss,acc, tock-tick))\n",
    "    print('saving model')\n",
    "    save(name + str(epoch_num))\n",
    "\n",
    "print(\"Total time elapsed: {:.0f} minutes\".format((tock-tick)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab len is 5226\n",
      "Warning: 47/930911 words are not in dictionary, thus set UNK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/cs/undergrad/2019/gnosborn/nlp/env/lib/python3.6/site-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 47/930911 words are not in dictionary, thus set UNK\n",
      "skip thought encoding dataset\n",
      "[============================================================] 99.9% ...\r"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data_set = None\n",
    "test_data_set = LastSentenceDataset(file='story_cloze_data/cloze_test_test__spring2016 - cloze_test_ALL_test.csv',vocab=voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(name):\n",
    "    l_model = LSModel()\n",
    "    l_model.load_state_dict(torch.load('saved_models/{}.save'.format(name)))\n",
    "    return l_model\n",
    "#model = load('LS_adagrad5')\n",
    "#print('model',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5793693212185996"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(test_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
